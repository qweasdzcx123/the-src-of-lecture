Beyond Sparsity: Tree Regularization of Deep Models for Interpretability
Mike Wu1, Michael C. Hughes2, Sonali Parbhoo3, Maurizio Zazzi4, Volker Roth3, and Finale Doshi-Velez2
1Stanford University, wumike@cs.stanford.edu 2Harvard University SEAS, mike@michaelchughes.com, ﬁnale@seas.harvard.edu
3University of Basel, {sonali.parbhoo,volker.roth}@unibas.ch 4University of Siena, maurizio.zazzi@unisi.it

arXiv:1711.06178v1 [stat.ML] 16 Nov 2017

Abstract
The lack of interpretability remains a key barrier to the adoption of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Speciﬁcally, we train deep time-series models so their classprobability predictions have high accuracy while being closely modeled by decision trees with few nodes. Using intuitive toy examples as well as medical tasks for treating sepsis and HIV, we demonstrate that this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacriﬁcing predictive power.
1 Introduction
Deep models have become the de-facto approach for prediction in a variety of applications such as image classiﬁcation (e.g. (Krizhevsky, Sutskever, and Hinton 2012)) and machine translation (e.g. (Bahdanau, Cho, and Bengio 2014; Sutskever, Vinyals, and Le 2014)). However, many practitioners are reluctant to adopt deep models because their predictions are difﬁcult to interpret. In this work, we seek a speciﬁc form of interpretability known as human-simulability. A human-simulatable model is one in which a human user can “take in input data together with the parameters of the model and in reasonable time step through every calculation required to produce a prediction” (Lipton 2016). For example, small decision trees with only a few nodes are easy for humans to simulate and thus understand and trust. In contrast, even simple deep models like multi-layer perceptrons with a few dozen units can have far too many parameters and connections for a human to easily step through. Deep models for sequences are even more challenging. Of course, decision trees with too many nodes are also hard to simulate. Our key research question is: can we create deep models that are well-approximated by compact, human-simulatable models?
The question of creating accurate yet human-simulatable models is an important one, because in many domains simulatability is paramount. For example, despite advances in deep learning for clinical decision support (e.g. (Miotto et al.
A version of this work will appear in AAAI 2018 (https:// aaai.org/Conferences/AAAI-18/). This paper includes an extended appendix with supplementary material.

2016; Choi et al. 2016; Che et al. 2015)), the clinical community remains skeptical of machine learning systems (Chen and Asch 2017). Simulatability allows clinicians to audit predictions easily. They can manually inspect changes to outputs under slightly-perturbed inputs, check substeps against their expert knowledge, and identify when predictions are made due to systemic bias in the data rather than real causes. Similar needs for simulatability exist in many decision-critical domains such as disaster response or recidivism prediction.
To address this need for interpretability, a number of works have been developed to assist in the interpretation of alreadytrained models. Craven and Shavlik (1996) train decision trees that mimic the predictions of a ﬁxed, pretrained neural network, but do not train the network itself to be simpler. Other post-hoc interpretations typically typically evaluate the sensitivity of predictions to local perturbations of inputs or the input gradient (Ribeiro, Singh, and Guestrin 2016; Selvaraju et al. 2016; Adler et al. 2016; Lundberg and Lee 2016; Erhan et al. 2009). In parallel, research efforts have emphasized that simple lists of (perhaps locally) important features are not sufﬁcient: Singh, Ribeiro, and Guestrin (2016) provide explanations in the form of programs; Lakkaraju, Bach, and Leskovec (2016) learn decision sets and show beneﬁts over other rule-based methods.
These techniques focus on understanding already learned models, rather than ﬁnding models that are more interpretable. However, it is well-known that deep models often have multiple optima of similar predictive accuracy (Goodfellow, Bengio, and Courville 2016), and thus one might hope to ﬁnd more interpretable models with equal predictive accuracy. However, the ﬁeld of optimizing deep models for interpretability remains nascent. Ross, Hughes, and Doshi-Velez (2017) penalize input sensitivity to features marked as less relevant. Lei, Barzilay, and Jaakkola (2016) train deep models that make predictions from text and simultaneously highlight contiguous subsets of words, called a “rationale,” to justify each prediction. While both works optimize their deep models to expose relevant features, lists of features are not sufﬁcient to simulate the prediction.
Contributions. In this work, we take steps toward optimizing deep models for human-simulatability via a new model complexity penalty function we call tree regularization. Tree regularization favors models whose decision boundaries can

be well-approximated by small decision-trees, thus penalizing models that would require many calculations to simulate predictions. We ﬁrst demonstrate how this technique can be used to train simple multi-layer perceptrons to have tree-like decision boundaries. We then focus on time-series applications and show that gated recurrent unit (GRU) models trained with strong tree-regularization reach a high-accuracyat-low-complexity sweet spot that is not possible with any strength of L1 or L2 regularization. Prediction quality can be further boosted by training new hybrid models – GRUHMMs – which explain the residuals of interpretable discrete HMMs via tree-regularized GRUs. We further show that the approximate decision trees for our tree-regularized deep models are useful for human simulation and interpretability. We demonstrate our approach on a speech recognition task and two medical treatment prediction tasks for patients with sepsis in the intensive care unit (ICU) and for patients with human immunodeﬁciency virus (HIV). Throughout, we also show that standalone decision trees as a baseline are noticeably less accurate than our tree-regularized deep models. We have released an open-source Python toolbox to allow others to experiment with tree regularization 1.
Related work. While there is little work (as mentioned above) on optimizing models for interpretability, there are some related threads. The ﬁrst is model compression, which trains smaller models that perform similarly to large, blackbox models (e.g. (?; Hinton, Vinyals, and Dean 2015; Balan et al. 2015; Han et al. 2015)). Other efforts speciﬁcally train very sparse networks via L1 penalties (Zhang, Lee, and Jordan 2016) or even binary neural networks (Tang, Hua, and Wang 2017; Rastegari et al. 2016) with the goal of faster computation. Edge and node regularization is commonly used to improve prediction accuracy (Drucker and Le Cun 1992; Ochiai et al. 2017), and recently Hu et al. (2016) improve prediction accuracy by training neural networks so that predictions match a small list of known domain-speciﬁc ﬁrstorder logic rules. Sometimes, these regularizations—which all smooth or simplify decision boundaries—can have the effect of also improving interpretability. However, there is no guarantee that these regularizations will improve interpretability; we emphasize that speciﬁcally training deep models to have easily-simulatable decision boundaries is (to our knowledge) novel.
2 Background and Notation
We consider supervised learning tasks given datasets of N labeled examples, where each example (indexed by n) has an input feature vectors xn and a target output vector yn. We shall assume the targets yn are binary, though it is simple to extend to other types. When modeling time series, each example sequence n contains Tn timesteps indexed by t which each have a feature vector xnt and an output ynt. Formally, we write: xn = [xn1 . . . xnTn ] and yn = [yn1 . . . ynTn ]. Each value ynt could be prediction about the next timestep (e.g. the character at time t + 1) or some other task-related annotation (e.g. if the patient became septic at time t).
1 https://github.com/dtak/tree- regularization- public

Simple neural networks. A multi-layer perceptron (MLP)
makes predictions yˆn of the target yn via a function yˆn(xn, W ), where the vector W represents all parameters of the network. Given a data set {(xn, yn)}, our goal is to learn the parameters W to minimize the objective

N

min λΨ(W ) + loss(yn, yˆn(xn, W ))

(1)

W

n=1

For binary targets yn, the logistic loss (binary cross entropy) is an effective choice. The regularization term Ψ(W ) can represent L1 or L2 penalties (e.g. (Drucker and Le Cun 1992; Goodfellow, Bengio, and Courville 2016; Ochiai et al. 2017)) or our new regularization.

Recurrent Neural Networks with Gated Recurrent Units.
A recurrent neural network (RNN) takes as input an arbitrary length sequence xn = [xn1 . . . xnTn ] and produces a “hidden state” sequence hn = [hn1 . . . hnTn ] of the same length as the input. Each hidden state vector at timestep t represents a location in a (possibly low-dimensional) “state space” with K dimensions: hnt ∈ RK . RNNs perform sequential nonlinear embedding of the form hnt = f (xnt, hnt−1) in hope that the state space location hnt is a useful summary statistic for making predictions of the target ynt at timestep t.
Many different variants of the transition function architecture f have been proposed to solve the challenge of capturing
long-term dependencies. In this paper, we use gated recurrent
units (GRUs) (Cho et al. 2014), which are simpler than other
alternatives such as long short-term memory units (LSTMs)
(Hochreiter and Schmidhuber 1997). While GRUs are con-
venient, any differentiable RNN architecture is compatible
with our new tree-regularization approach.
Below we describe the evolution of a single GRU sequence, dropping the sequence index n for readability. The GRU transition function f produces the state vector ht = [ht1 . . . htK ] from a previous state ht−1 and an input vector xt, via the following feed-forward architecture:

output state : htk = (1 − ztk)ht−1,k + zt,kh˜tk (2)

candidate state : h˜tk = tanh(Vkhxt + Ukh(rt update gate : ztk = σ(Vkzxt + Ukzht−1) reset gate : rtk = σ(Vkrxt + Ukrht−1)

ht−1))

The internal network nodes include candidate state gates h˜, update gates z and reset gates r which have the same cardinalty as the state vector h. Reset gates allow the network to forget past state vectors when set near zero via the logistic sigmoid nonlinearity σ(·). Update gates allow the network to either pass along the previous state vector unchanged or use the new candidate state vector instead. This architecture is diagrammed in Figure 1.
The predicted probability of the binary label yt for time t is a sigmoid transformation of the state at time t:

yˆt = σ(wT ht)

(3)

Here, weight vector w ∈ RK represents the parameters of this output layer. We denote the parameters for the entire

2

yt ht λ

h t-1

sigm

1-

rt
sigm

zt
sigm

~h t
tanh

Algorithm 1 Average-Path-Length Cost Function

Require:

yˆ(·, W ) : binary prediction function, with parameters W

D = {xn}Nn=1 : reference dataset with N examples 1: function Ω(W )

2: tree ← TRAINTREE({xn, yˆ(xn, W )})

3:

return

1 N

n PATHLENGTH(tree, xn)

x t-1
Figure 1: Diagram of gated recurrent unit (GRU) used for each timestep our neural time-series model. The orange triangle indicates the predicted output yˆt at time t.

GRU-RNN model as W = (w, U, V ), concatenating all component parameters. We can train GRU-RNN time-series models (hereafter often just called GRUs) via the following loss minimization objective:

N Tn

min λΨ(W ) +

loss(ynt, yˆnt(xn, W )) (4)

W

n=1 n=1

where again Ψ(W ) deﬁnes a regularization cost.

3 Tree Regularization for Deep Models
We now propose a novel tree regularization function Ω(W ) for the parameters of a differentiable model which attempts to penalize models whose predictions are not easily simulatable. Of course, it is difﬁcult to measure “simulatability” directly for an arbitrary network, so we take inspiration from decision trees. Our chosen method has two stages: ﬁrst, ﬁnd a single binary decision tree which accurately reproduces the network’s thresholded binary predictions yˆn given input xn. Second, measure the complexity of this decision tree as the output of Ω(W ). We measure complexity as the average decision path length—the average number of decision nodes that must be touched to make a prediction for an input example xn. We compute the average with respect to some designated reference dataset of example inputs D = {xn} from the training set. While many ways to measure complexity exist, we ﬁnd average path length is most relevant to our notion of simulatability. Remember that for us, human simulation requires stepping through every calculation required to make a prediction. Average path length exactly counts the number of true-or-false boolean calculations needed to make an average prediction, assuming the model is a decision tree. Total number of nodes could be used as a metric, but might penalize more accurate trees that have short paths for most examples but need more involved logic for few outliers.
Our true-average-path-length cost function Ω(W ) is detailed in Alg. 1. It requires two subroutines, TRAINTREE and PATHLENGTH. TRAINTREE trains a binary decision tree to accurately reproduce the provided labeled examples {xn, yˆn}. We use the DecisionTree module distributed in Python’s scikit-learn (Pedregosa et al. 2011) with post-pruning to simplify the tree. These trees can give probabilistic predictions at each leaf. (Complete decision-tree training details are in the

supplement.) Next, PATHLENGTH counts how many nodes are needed to make a speciﬁc input to an output node in the provided decision tree. In our evaluations, we will apply our average-decision-tree-path-length regularization, or simply “tree regularization,” to several neural models. Alg. 1 deﬁnes our average-path-length cost function Ω(W ), which can be plugged into the abstract regularization term Ψ(W ) in the objectives in equations 1 and 4.

Making the Decision-Tree Loss Differentiable Training decision trees is not differentiable, and thus Ω(W ) as deﬁned in Alg. 1 is not differentiable with respect to the network parameters W (unlike standard regularizers such as the L1 or L2 norm). While one could resort to derivative-free optimization techniques (Audet and Kokkolaras 2016), gradient descent has been an extremely fast and robust way of training networks (Goodfellow, Bengio, and Courville 2016).
A key technical contribution of our work is introducing and training a surrogate regularization function Ωˆ (W ) : supp(W ) → R+ to map each candidate neural model parameter vector W to an estimate of the average-path-length. Our approximate function Ωˆ is implemented as a standalone multi-layer perceptron network and is thus differentiable. Let vector ξ of size k denote the parameters of this chosen MLP approximator. We can train Ωˆ to be a good estimator by minimizing a squared error loss function:

min
ξ

Jj=1(Ω(Wj) − Ωˆ (Wj, ξ))2 + ||ξ||22

(5)

where Wj are the entire set of parameters for our model, > 0 is a regularization strength, and we assume we have
a dataset of J known parameter vectors and their associated true path-lengths: {Wj, Ω(Wj)}Jj=1. This dataset can be assembled using the candidate W vectors obtained while
training our target neural model yˆ(·, W ), as well as by evalu-
ating Ω(W ) for randomly generated W . Importantly, one can train the surrogate function Ωˆ in parallel with our network.
In the supplement, we show evidence that our surrogate predictor Ωˆ (·) tracks the true average path length as we train the
target predictor yˆ(·, W ).

Training the Surrogate Loss Even moderately-sized
GRUs can have parameter vectors W with thousands of
dimensions. Our labeled dataset for surrogate training – {Wj, Ω(Wj)}Jj=1—will only have one Wj example from each target network training iteration. Thus, in early itera-
tions, we will have only few examples from which to learn a good surrogate function Ωˆ (W ). We resolve this challenge

3

via augmenting our training set with additional examples: We randomly sample weight vectors W and calculate the true average path length Ω(W ), and we also perform several random restarts on the unregularized GRU and use those weights in our training set.
A second challenge occurs later in training: as the model parameters W shift away from their initial values, those early parameters may not be as relevant in characterizing the current decision function of the GRU. To address this, for each epoch, we use examples only from the past E epochs (in addition to augmentation), where in practice, E is empirically chosen. Using examples from a ﬁxed window of epochs also speeds up training. The supplement shows a comparison of the importance of these heuristics for efﬁcient and accurate training—empirically, data augmentation for stabilizing surrogate training allows us to scale to GRUs with 100s of nodes. GRUs of this size are sufﬁcient for many real problems, such as those we encounter in healthcare domains.
Typically, we use J = 50 labeled pairs for surrogate training for toy datasets and J = 100 for real world datasets. Optimization of our surrogate objective is done via gradient descent. We use Autograd to compute gradients of the loss in Eq. (5) with respect to ξ, then use Adam to compute descent directions with step sizes set to 0.01 for toy datasets and 0.001 for real world datasets.
4 Tree-Regularized MLPs: A Demonstration
While time-series models are the main focus of this work, we ﬁrst demonstrate tree regularization on a simple binary classiﬁcation task to build intuition. We call this task the 2D Parabola problem, because as Fig. 2(a) shows, the training data consists of 2D input points whose two-class decision boundary is roughly shaped like a parabola. The true decision function is deﬁned by y = 5 ∗ (x − 0.5)2 + 0.4. We sampled 500 input points xn uniformly within the unit square [0, 1] × [0, 1] and labeled those above the decision function as positive. To make it easy for models to overﬁt, we ﬂipped 10% of the points in a region near the boundary. A random 30% were held out for testing.
For the classiﬁer yˆ, we train a 3-layer MLP with 100 ﬁrst layer nodes, 100 second layer nodes, and 10 third layer nodes. This MLP is intentionally overly expressive to encourage overﬁtting and expose the impact of different forms of regularization: our proposed tree regularization Ψ(W ) = Ωˆ (W ) and two baselines: an L2 penalty on the weights Ψ(W ) = ||W ||2, and an L1 penalty on the weights Ψ(W ) = ||W ||1. For each regularization function, we train models at many different regularization strengths λ chosen to explore the full range of decision boundary complexities possible under each technique.
For our tree regularization, we model our surrogate Ωˆ (W ) with a 1-hidden layer MLP with 25 units. We ﬁnd this simple architecture works well, but certainly more complex MLPs could could be used on more complex problems. The objective in equation 1 was optimized via Adam gradient descent (Kingma and Ba 2014) using a batch size of 100 and a learning rate of 1e-3 for 250 epochs, and hyperparameters were set via cross validation using grid search (see supplement for

full experimental details). Fig. 2 (b) shows the each trained model as a single point
in a 2D ﬁtness space: the x-axis measures model complexity via our average-path-length metric, and the y-axis measures AUC prediction performance. These results show that simple L1 or L2 regularization does not produce models with both small node count and good predictions at any value of the regularization strength λ. As expected, large λ values for L1 and L2 only produce far-too-simple linear decision boundaries with poor accuracies. In contrast, our proposed tree regularization directly optimizes the MLP to have simple tree-like boundaries at high λ values which can still yield good predictions.
The lower panes of Fig. 2 shows these boundaries. Our tree regularization is uniquely able to create axis-aligned functions, because decision trees prefer functions that are axis-aligned splits. These axis-aligned functions require very few nodes but are more effective than L1 and L2 counterparts. The L1 boundary is more sharp, whereas the L2 is more round.
5 Tree-Regularized Time-Series Models
We now evaluate our tree-regularization approach on timeseries models. We focus on GRU-RNN models, with some later experiments on new hybrid GRU-HMM models. As with the MLP, each regularization technique (tree, L2, L1) can be applied to the output node of the GRU across a range of strength parameters λ. Importantly, Algorithm 1 can compute the average-decision-tree-path-length for any ﬁxed deep model given its parameters, and can hence be used to measure decision boundary complexity under any regularization, including L1 or L2. This means that when training any model, we can track both the predictive performance (as measured by area-under-the-ROC-curve (AUC); higher values mean better predictions), as well as the complexity of the decision tree required to explain each model (as measured by our average path length metric; lower values mean more interpretable models). We also show results for a baseline standalone decision tree classiﬁer without any associated deep model, sweeping a range of parameters controlling leaf size to explore how this baseline trades off path length and prediction quality. Further details of our experimental protocol are in the supplement, as well as more extensive results with additional baselines.
5.1 Tasks
Synthetic Task: Signal-and-noise HMM We generated a toy dataset of N = 100 sequences, each with T = 50 timesteps. Each timestep has a data vector xnt of 14 binary features and a single binary output label ynt. The data comes from two separate HMM processes. First, a “signal” HMM generates the ﬁrst 7 data dimensions from 5 well-separated states. Second, an independent “noise” HMM generates the remaining 7 data dimensions from a different set of 5 states. Each timestep’s output label ynt is produced by a rule involving both the signal data and the signal hidden state: the target is 1 at timestep t only if both the ﬁrst signal state is active and the ﬁrst observation is turned on. We deliberately designed

4

1.0 0.8 0.6 0.4 0.2 0.00.0 0.2 0.4 0.6 0.8 1.0
(a) Training Data and Binary Class Labels for 2D Parabola
1.0

0.8

MLP (L2)

MLP (L1)

0.6

MLP (Tree)

Decision Tree

0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 Average Path Length

(b) Prediction quality and complexity as reg. strength λ varies

L1 0.0005

L1 0.002

L1 0.0025

L1 0.0035

L1 0.004

L1 0.0045

AUC (Test)

(c) Decision Boundaries with L1 regularization

L2 0.05

L2 0.8

L2 0.9

L2 1.0

L2 1.30

L2 2.0

(d) Decision Boundaries with L2 regularization

Tree 0.01

Tree 100.0

Tree 700.0

Tree 9500.0

Tree 12000.0

Tree 15000.0

(e) Decision Boundaries Tree regularization
Figure 2: 2D Parabola task: (a) Each training data point in 2D space, overlaid with true parabolic class boundary. (b): Each method’s prediction quality (AUC) and complexity (path length) metrics, across range of regularization strength λ. In the small path length regime between 0 and 5, tree regularization produces models with higher AUC than L1 or L2. (c-e): Decision boundaries (black lines) have qualitatively different shapes for different regularization schemes, as regularization strength λ increases. We color predictions as true positive (red), true negative (yellow), false negative (green), and false positive (blue).
the generation process so that neither logistic regression with x as features nor an RNN model that makes predictions from hidden states alone can perfectly separate this data.
Real-World Tasks: We tested our approach on several real tasks: predicting medical outcomes of hospitalized septic patients, predicting HIV therapy outcomes, and identifying stop phonemes in English speech recordings. To normalize scales, we independently standardized features x via z-scoring.
• Sepsis Critical Care: We study time-series data for 11 786

septic ICU patients from the public MIMIC III dataset (Johnson et al. 2016). We observe at each hour t a data vector xnt of 35 vital signs and lab results as well as a label vector ynt of 5 binary outcomes. Hourly data xnt measures continuous features such as respiration rate (RR), blood oxygen levels (paO2), ﬂuid levels, and more. Hourly binary labels ynt include whether the patient died in hospital and if mechanical ventilation was applied. Models are trained to predict all 5 output dimensions concurrently from one shared embedding. The average sequence length is 15 hours. 7 070 patients are used in training, 1 769 for validation, and 294 for test.
• HIV Therapy Outcome (HIV): We use the EuResist Integrated Database (Zazzi et al. 2012) for 53 236 patients diagnosed with HIV. We consider 4-6 month intervals (corresponding to hospital visits) as time steps. Each data vector xnt has 40 features, including blood counts, viral load measurements and lab results. Each output vector ynt has 15 binary labels, including whether a therapy was successful in reducing viral load to below detection limits, if therapy caused CD4 blood cell counts to drop to dangerous levels (indicating AIDS), or if the patient suffered adherence issues to medication. The average sequence length is 14 steps. 37 618 patients are used for training; 7 986 for testing, and 7 632 for validation.
• Phonetic Speech (TIMIT): We have recordings of 630 speakers of eight major dialects of American English reading ten phonetically rich sentences (Garofolo et al. 1993). Each sentence contains time-aligned transcriptions of 60 phonemes. We focus on distinguishing stop phonemes (those that stop the ﬂow of air, such as “b” or “g”) from non-stops. Each timestep has one binary label ynt indicating if a stop phoneme occurs or not. Each input xnt has 26 continuous features: the acoustic signal’s Mel-frequency cepstral coefﬁcients and derivatives. There are 6 303 sequences, split into 3 697 for training, 925 for validation, and 1 681 for testing. The average length is 614.
5.2 Results
The major conclusions of our experiments comparing GRUs with various regularizations are outlined below.
Tree-regularized models have fewer nodes than other forms of regularization. Across tasks, we see that in the target regime of small decision trees (low average-path lengths), our proposed tree-regularization achieves higher prediction quality (higher AUCs). In the signal-and-noise HMM task, tree regularization (green line in Fig. 3(d)) achieves AUC values near 0.9 when its trees have an average path length of 10. Similar models with L1 or L2 regularization reach this AUC only with trees that are nearly double in complexity (path length over 25). On the Sepsis task (Fig. 4) we see AUC gains of 0.05-0.1 at path lengths of 2-10. On the TIMIT task (Fig. 5a), we see AUC gains of 0.05-0.1 at path lengths of 20-30. Finally, on the HIV CD4 blood cell count task in Fig. 5b, we see AUC differences of between 0.03 and 0.15 for path lengths of 10-15. The HIV adherence task in

5

X[0] <= 0.5 value = [3897, 1103]
class = off

True

False

value = [2546, 0] class = off

X[4] <= 0.5 value = [1351, 1103]
class = off

X[3] <= 0.5 value = [902, 1103]
class = on

value = [449, 0] class = off

X[6] <= 0.5 value = [902, 516]
class = off

value = [0, 587] class = on

X[5] <= 0.5 value = [741, 516]
class = off

value = [161, 0] class = off

X[11] <= 0.5 value = [588, 516]
class = off

value = [153, 0] class = off

X[1] <= 0.5 value = [254, 516]
class = on

value = [334, 0] class = off

X[8] <= 0.5 value = [112, 280]
class = on

X[9] <= 0.5 value = [142, 236]
class = on

value = [0, 280] class = on

value = [112, 0] class = off

value = [0, 236] class = on

value = [142, 0] class = off

X[0] <= 0.5 value = [4439, 561]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1893, 561]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [149, 561]
class = on

X[7] <= 0.5 value = [26, 561]
class = on

value = [123, 0] class = off

value = [0, 537] class = on

value = [26, 24] class = off

(a) GRU λ = 1

(b) GRU λ = 800

X[0] <= 0.5 value = [4413, 587]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1867, 587]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [123, 587]
class = on

value = [0, 587] class = on

value = [123, 0] class = off

(c) GRU λ = 1 000

AUC (Test)

1.0

0.9

0.8

0.7

GRU (L1)

GRU (L2)

0.6

GRU (Tree)

Decision Tree

0.50

10

20

30

40

Average Path Length

(d) GRU

Figure 3: Toy Signal-and-Noise HMM Task: (a)-(c) Decision trees trained to mimic predictions of GRU models with 25 hidden states at different regularization strengths λ; as expected, increasing λ decreases the size of the learned trees (see supplement for more trees). Decision tree (c) suggests the model learns to predict positive output (blue) if and only if “x[0] == 1 and x[3] == 1 and x[4] == 0”, which is consistent with the true rule we used to generate labels: assign positive label only if ﬁrst dimension is on (x[0] == 1) and ﬁrst state is active (emission probabilities for this state: [.5 .5 .5 .5 0 . . .]). (d) Tree-regularized GRU models reach a sweet spot of small path lengths yet high AUC predictions that alternatives cannot reach at any tested value of λ.

AUC (Test) AUC (Test)

0.7

0.6
0.5 0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree

10

20

30

Average Path Length

(a) In-Hospital Mortality

age <= 64.212 value = [35299, 65553] class = died_in_hosp:OFF

True

False

BUN <= 28.163 value = [30660, 14493] class = died_in_hosp:ON

BUN <= 24.153 value = [4639, 51060] class = died_in_hosp:OFF

Platelets_count <= 101.882 value = [29033, 2784] class = died_in_hosp:ON

BUN <= 49.909 value = [1627, 11709] class = died_in_hosp:OFF

age <= 74.354 value = [4639, 19225] class = died_in_hosp:OFF

value = [0, 31835] class = died_in_hosp:OFF

age <= 51.728 value = [1427, 2784] class = died_in_hosp:OFF

value = [27606, 0] class = died_in_hosp:ON

age <= 48.95 value = [1627, 6324] class = died_in_hosp:OFF

value = [0, 5385] class = died_in_hosp:OFF

INR <= 1.437 value = [4639, 5882] class = died_in_hosp:OFF

value = [0, 13343] class = died_in_hosp:OFF

value = [1427, 569]

value = [0, 2215]

class = died_in_hosp:ON class = died_in_hosp:OFF

Arterial_BE <= -0.943 value = [1627, 809] class = died_in_hosp:ON

value = [0, 5515] class = died_in_hosp:OFF

Hb <= 9.907 value = [4639, 3299] class = died_in_hosp:ON

value = [0, 2583] class = died_in_hosp:OFF

value = [486, 514]

value = [1141, 295]

class = died_in_hosp:OFF class = died_in_hosp:ON

Platelets_count <= 289.44

HR <= 94.223

value = [742, 2610]

value = [3897, 689]

class = died_in_hosp:OFF class = died_in_hosp:ON

value = [0, 2203]

value = [742, 407]

value = [3241, 0]

value = [656, 689]

class = died_in_hosp:OFF class = died_in_hosp:ON class = died_in_hosp:ON class = died_in_hosp:OFF

(b) In-Hospital Mortality

0.9

0.8

0.7
0.6
0.5 0.0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree
2.5 5.0 7.5 10.0 12.5 Average Path Length

(c) Mechanical Ventilation

GCS <= 13.998 value = [14985, 85867] class = mechvent:OFF

True

False

value = [0, 67874] class = mechvent:OFF

FiO2_100 <= 37.002 value = [14985, 17993] class = mechvent:OFF

CO2_mEqL <= 31.131 value = [13112, 599] class = mechvent:ON

FiO2_100 <= 46.663 value = [1873, 17394] class = mechvent:OFF

value = [12674, 0] class = mechvent:ON

value = [438, 599] class = mechvent:OFF

RR <= 19.136 value = [1873, 5146] class = mechvent:OFF

value = [0, 12248] class = mechvent:OFF

value = [0, 2969] class = mechvent:OFF

CO2_mEqL <= 27.007 value = [1873, 2177] class = mechvent:OFF

paO2 <= 112.252 value = [1330, 1185] class = mechvent:ON

value = [543, 992] class = mechvent:OFF

value = [885, 541] class = mechvent:ON

value = [445, 644] class = mechvent:OFF

(d) Mechanical Ventilation

Figure 4: Sepsis task: Study of different regularization techniques for GRU model with 100 states, trained to jointly predict 5 binary outcomes. Panels (a) and (c) show AUC vs. average path length for 2 of the 5 outcomes (remainder in the supplement); in both cases, tree-regularization provides higher accuracy in the target regime of low-complexity decision trees. Panels (b) and (d) show the associated decision trees for λ = 2 000; these were found by clinically interpretable by an ICU clinician (see main text).

AUC (Test) AUC (Test) AUC (Test)

1.0

0.9

0.8

0.7

GRU (L1)

GRU (L2)

0.6

GRU (Tree)

Decision Tree

0.5

20

40

60

Average path Length

(a) TIMIT Stop Phonemes

0.70

0.65

GRU (L1) 0.60
GRU (L2)

GRU (Tree)

0.55

Decision Tree

10.0 12.5 15.0 17.5 20.0 Average Path Length

(b) HIV: CD4+ ≤ 200 cells/ml

0.8

0.7

GRU (L1)

0.6

GRU (L2)

GRU (Tree)

Decision Tree

15.0 17.5 20.0 22.5 25.0 27.5 Average Path Length

Baseline VL <= 45.68 value = [33957, 39928] class = Poor Adherence: OFF

value = [146, 3524] class = Poor Adherence: OFF

Baseline VL <= 900486.29 value = [33811, 36404]
class = Poor Adherence: ON

No. of prior treatment lines < 4.0 value = [29541, 31271]
class = Poor Adherence: OFF

Baseline CD4 <216.94 value = [4270, 5133] class = Poor Adherence: ON

value = [27262, 21472] class = Poor Adherence: OFF

value = [2279, 9799] class = Poor Adherence: ON

Age <38.0 value = [2623, 4666] class = Poor Adherence: ON

value = [1647, 467] class = Poor Adherence: ON

value = [1306, 2219] class = Poor Adherence: ON

Sex <= 0.5 value = [1317, 2447] class = Poor Adherence: ON

IDU <= 0.5 value = [71, 412] class = Poor Adherence: OFF

value = [1246, 2035] class = Poor Adherence: ON

value = [44, 13] class = Poor Adherence: ON

value = [27, 399] class = Poor Adherence: OFF

(c) HIV Therapy Adherence (d) HIV Therapy Adherence

Figure 5: TIMIT and HIV tasks: Study of different regularization techniques for GRU model with 75 states. Panels (a)-(c) are tradeoff curves showing how AUC predictive power and decision-tree complexity evolve with increasing regularization strength under L1, L2 or tree regularization on both TIMIT and HIV tasks. The GRU is trained to jointly predict 15 binary outcomes for HIV, of which 2 are shown here in Panels (b) - (c). The GRU’s decision tree proxy for HIV Adherence is shown in (d).

6

Fig. 5d has AUC gains of between 0.03 and 0.05 in the path length range of 19 to 25 while at smaller paths all methods are quite poor, indicating the problem’s difﬁculty. Overall, these AUC gains are particularly useful in determining how to administer subsequent HIV therapies.
We emphasize that our tree-regularization usually achieves a sweet spot of high AUCs at short path lengths not possible with standalone decision trees (orange lines), L1-regularized deep models (red lines) or L2-regularized deep models (blue lines). In unshown experiments, we also tested elastic net regularization (Zou and Hastie 2005), a linear combination of L1 and L2 penalities. We found elastic nets to follow the same trend lines as L1 and L2, with no visible differences. In domains where human-simulatability is required, increases in prediction accuracy in the small-complexity regime can mean the difference between models that provide value on a task and models that are unusable, either because performance is too poor or predictions are uninterpretable.
Our learned decision tree proxies are interpretable. Across all tasks, the decision trees which mimic the predictions of tree-regularized deep models are small enough to simulate by hand (path length ≤ 25) and help users grasp the model’s nonlinear prediction logic. Intuitively, the trees for our synthetic task in Fig. 3(a)-(c) decrease in size as the strength λ increases. The logic of these trees also matches the true labeling process: even the simplest tree (c) checks a relevant subset of input dimensions necessary to verify that both the ﬁrst state and the ﬁrst output dimension are active.
In Fig. 4, we show decision tree proxies for our deep models on two sepsis prediction tasks: mortality and need for ventilation. We consulted a clinical expert on sepsis treatment, who noted that the trees helped him understand what the models might be doing and thus determine if he would trust the deep model. For example, he said that using FiO2, RR, CO2 and paO2 to predict need for mechanical ventilation (Fig. 4d) was sensible, as these all measure breathing quality. In contrast, the in-hospital mortality tree (Fig. 4b) predicts that some young patients with no organ failure have high mortality rates while other young patients with organ failure have low mortality. These counter-intuitive results led to hypotheses about how uncaptured variables impact the training process. Such reasoning would not be possible from simple sensitivity analyses of the deep model.
Finally, we have veriﬁed that the decision tree proxies of our tree-regularized deep models of the HIV task in Fig. 5d are interpretable for understanding why a patient has trouble adhering to a prescription; that is, taking drugs regularly as directed. Our clinical collaborators conﬁrm that the baseline viral load and number of prior treatment lines, which are prominent attributes for the decisions in Fig. 5d, are useful predictors of a patient with adherence issues. Several medical studies (Langford, Ananworanich, and Cooper 2007; Socas et al. 2011) suggest that patients with higher baseline viral loads tend to have faster disease progression, and hence have to take several drug cocktails to combat resistance. Juggling many drugs typically makes it difﬁcult for these patients to adhere as directed. We hope interpretable predictive

models for adherence could help assess a patient’s overall prognosis (Paterson et al. 2000) and offer opportunities for intervention (e.g. with alternative single-tablet regimens).
Decision trees trained to mimic deep models make faithful predictions. Across datasets, we ﬁnd that each treeregularized deep time-series model has predictions that agree with its corresponding decision tree proxy in about 85-90% of test examples. Table 1 shows exact ﬁdelty scores for each dataset. Thus, the simulatable paths of the decision tree will be trustworthy in a majority of cases.
Practical runtimes for tree regularization are less than twice that of simpler L2. While our tree-regularized GRU with 10 states takes 3977 seconds per epoch on TIMIT, a similar L2-regularized GRU takes 2116 seconds per epoch. Thus, our new method has cost less than twice the baseline even when the surrogate is serially computed. Because the surrogate Ωˆ (W ) will in general be a much smaller model than the predictor yˆ(x, W ), we expect one could get faster per-epoch times by parallelizing the creation of (W, Ω(W )) training pairs and the training of the surrogate Ωˆ (W ). Additionally, 3977 seconds includes the time needed to train the surrogate. In practice, we do this sparingly, only once every 25 epochs, yielding an amortized per-epoch cost of 2191 seconds (more runtime results are in the supplement).
Decision trees are stable over multiple optimization runs. When tree regularization is strong (high λ), the decision trees trained to match the predictions of deep models are stable. For both signal-and-noise and sepsis tasks, multiple runs from different random restarts have nearly identical tree shape and size, perhaps differing by a few nodes. This stability is crucial to building trust in our method. On the signal-andnoise task (λ = 7000), 7 of 10 independent runs with random initializations resulted in trees of exactly the same structure, and the others closely resembled those sharing the same subtrees and features (more details in supplement).
The deep residual GRU-HMM achieves high AUC with less complexity. So far, we have focused on regularizing standard deep models, such as MLPs or GRUs. Another option is to use a deep model as a residual on another model that is already interpretable: for example, discrete HMMs partition timesteps into clusters, each of which can be inspected, but its predictions might have limited accuracy. In Fig. 6, we show the performance of jointly training a GRU-HMM, a new model which combines an HMM with a tree-regularized GRU to improve its predictions (details and further results in the supplement). Here, the ideal path length is zero, indicating only the HMM makes predictions. For small averagepath-lengths, the GRU-HMM improves the original HMM’s predictions and has simulatability gains over earlier GRUs. On the mechanical ventilation task, the GRU-HMM requires an average path length of only 28 to reach AUC of 0.88, while the GRU alone with the same number of states requires a path length of 60 to reach the same AUC. This suggests that

7

Dataset signal-and-noise HMM SEPSIS (In-Hospital Mortality) SEPSIS (90-Day Mortality) SEPSIS (Mech. Vent.) SEPSIS (Median Vaso.) SEPSIS (Max Vaso.) HIV (CD4+ below 200) HIV (Therapy Success) HIV (Mortality) HIV (Poor Adherence) HIV (AIDS Onset) TIMIT

Fidelity 0.88 0.81 0.88 0.90 0.92 0.93 0.84 0.88 0.93 0.90 0.93 0.85

Table 1: Fidelity of predictions from our trained deep GRURNN and its corresponding decision tree. Fidelity is deﬁned as the percentage of test examples on which the prediction made by a tree agrees with the deep model (Craven and Shavlik 1996). We used 20 hidden GRU states for signal-andnoise task, 50 states for all others.

jointly-trained deep residual models may provide even better interpretability.

AUC (Test)

0.955 0.950 0.945 0.940 0.9350

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)
5 10 15 20 25 30 Average Path Length

(a) Signal-and-noise 20+5

0.90

0.88

0.86
0.84
0.82 0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

2

4

6

8 10

Average Path Length

(c) Mech. Vent. 50+50

A8C (THst)

AUC (Test)

0.75 0.74 0.73 0.72
0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

10

20

30

Average Path Length

(b) In-Hosp. Mort. 50+50

0.95 0.94 0.93 0.92
0

G58-H00 (L1) G58-H00 (L2) G58-H00 (TUHH)

20

40

60

80

AvHUagH 3ath LHngth

(d) Stop Phonemes 50+25

AUC (Test)

Figure 6: Fitness curves for the GRU-HMM, showing prediction quality (AUC) vs. complexity (path length) across range of regularization strengths λ. Captions show the number of HMM states plus the number of GRU states. See earlier ﬁgures to compare these GRU-HMM numbers to simpler GRU and decision tree baselines.

6 Discussion and Conclusion
We have introduced a novel tree-regularization technique that encourages the complex decision boundaries of any differentiable model to be well-approximated by human-simulatable functions, allowing domain experts to quickly understand and approximately compute what the more complex model is doing. Overall, our training procedure is robust and efﬁcient; future work could continue to explore and increase the

stability of the learned models as well as identify ways to apply our approach to situations in which the inputs are not inherently interpretable (e.g. pixels in an image).
Across three complex, real-world domains – HIV treatment, sepsis treatment, and human speech processing – our tree-regularized models provide gains in prediction accuracy in the regime of simpler, approximately human-simulatable models. Future work could apply tree regularization to local, example-speciﬁc approximations of a loss (Ribeiro, Singh, and Guestrin 2016) or to representation learning tasks (encouraging embeddings with simple boundaries). More broadly, our general training procedure could apply treeregularization or other procedure-regularization to a wide class of popular models, helping us move beyond sparsity toward models humans can easily simulate and thus trust.
Acknowledgements
MW is supported by the U.S. National Science Foundation. MCH is supported by Oracle Labs. SP is supported by the Swiss National Science Foundation project 51MRP0 158328. The authors thank the EuResist Network for providing HIV data for this study, and thank Matthieu Komorowski for the preprocessed sepsis data (Raghu et al. 2017). Computations were supported by the FAS Research Computing Group at Harvard and sciCORE (http://scicore.unibas.ch/) scientiﬁc computing core facility at University of Basel.
References
Adler, P.; Falk, C.; Friedler, S. A.; Rybeck, G.; Scheidegger, C.; Smith, B.; and Venkatasubramanian, S. 2016. Auditing black-box models for indirect inﬂuence. In ICDM.
Audet, C., and Kokkolaras, M. 2016. Blackbox and derivative-free optimization: theory, algorithms and applications. Springer.
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.
Balan, A. K.; Rathod, V.; Murphy, K. P.; and Welling, M. 2015. Bayesian dark knowledge. In NIPS.
Che, Z.; Kale, D.; Li, W.; Bahadori, M. T.; and Liu, Y. 2015. Deep computational phenotyping. In KDD.
Chen, J. H., and Asch, S. M. 2017. Machine learning and prediction in medicinebeyond the peak of inﬂated expectations. N Engl J Med 376(26):2507–2509.
Cho, K.; Gulcehre, B. v. M. C.; Bahdanau, D.; Schwenk, F. B. H.; and Bengio, Y. 2014. Learning phrase representations using RNN encoder–decoder for statistical machine translation. In EMLNP.
Choi, E.; Bahadori, M. T.; Schuetz, A.; Stewart, W. F.; and Sun, J. 2016. Doctor AI: Predicting clinical events via recurrent neural networks. In Machine Learning for Healthcare Conference.
Craven, M., and Shavlik, J. W. 1996. Extracting treestructured representations of trained networks. In NIPS.
Drucker, H., and Le Cun, Y. 1992. Improving generalization performance using double backpropagation. IEEE Transactions on Neural Networks 3(6):991–997.

8

Erhan, D.; Bengio, Y.; Courville, A.; and Vincent, P. 2009. Visualizing higher-layer features of a deep network. Technical Report 1341, Department of Computer Science and Operations Research, University of Montreal.
Garofolo, J. S.; Lamel, L. F.; Fisher, W. M.; Fiscus, J. G.; Pallett, D. S.; Dahlgren, N. L.; and Zue, V. 1993. Timit acoustic-phonetic continuous speech corpus. Linguistic data consortium 10(5).
Goodfellow, I.; Bengio, Y.; and Courville, A. 2016. Deep Learning. MIT Press. http: //www.deeplearningbook.org.
Han, S.; Pool, J.; Tran, J.; and Dally, W. 2015. Learning both weights and connections for efﬁcient neural network. In NIPS.
Hinton, G.; Vinyals, O.; and Dean, J. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.
Hochreiter, S., and Schmidhuber, J. 1997. Long short-term memory. Neural computation 9(8):1735–1780.
Hu, Z.; Ma, X.; Liu, Z.; Hovy, E.; and Xing, E. 2016. Harnessing deep neural networks with logic rules. In ACL.
Johnson, A. E.; Pollard, T. J.; Shen, L.; Lehman, L. H.; Feng, M.; Ghassemi, M.; Moody, B.; Szolovits, P.; Celi, L. A.; and Mark, R. G. 2016. MIMIC-III, a freely accessible critical care database. Scientiﬁc Data 3.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. ImageNet classiﬁcation with deep convolutional neural networks. In NIPS.
Lakkaraju, H.; Bach, S. H.; and Leskovec, J. 2016. Interpretable decision sets: A joint framework for description and prediction. In KDD.
Langford, S. E.; Ananworanich, J.; and Cooper, D. A. 2007. Predictors of disease progression in hiv infection: a review. AIDS Research and Therapy 4(1):11.
Lei, T.; Barzilay, R.; and Jaakkola, T. 2016. Rationalizing neural predictions. arXiv preprint arXiv:1606.04155.
Lipton, Z. C. 2016. The mythos of model interpretability. In ICML Workshop on Human Interpretability in Machine Learning.
Lundberg, S., and Lee, S.-I. 2016. An unexpected unity among methods for interpreting model predictions. arXiv preprint arXiv:1611.07478.
Miotto, R.; Li, L.; Kidd, B. A.; and Dudley, J. T. 2016. Deep patient: An unsupervised representation to predict the future of patients from the electronic health records. Scientiﬁc Reports 6:26094.
Ochiai, T.; Matsuda, S.; Watanabe, H.; and Katagiri, S. 2017. Automatic node selection for deep neural networks using group lasso regularization. In ICASSP.
Paterson, D. L.; Swindells, S.; Mohr, J.; Brester, M.; Vergis, E. N.; Squier, C.; Wagener, M. M.; and Singh, N. 2000. Adherence to protease inhibitor therapy and outcomes in patients with hiv infection. Annals of internal medicine 133(1):21–30.

Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; et al. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825–2830.
Raghu, A.; Komorowski, M.; Celi, L. A.; Szolovits, P.; and Ghassemi, M. 2017. Continuous state-space models for optimal sepsis treatment-a deep reinforcement learning approach. In Machine Learning for Healthcare Conference.
Rastegari, M.; Ordonez, V.; Redmon, J.; and Farhadi, A. 2016. XNOR-Net: ImageNet classiﬁcation using binary convolutional neural networks. In ECCV.
Ribeiro, M. T.; Singh, S.; and Guestrin, C. 2016. Why should I trust you?: Explaining the predictions of any classiﬁer. In KDD.
Ross, A.; Hughes, M. C.; and Doshi-Velez, F. 2017. Right for the right reasons: Training differentiable models by constraining their explanations. In IJCAI.
Selvaraju, R. R.; Das, A.; Vedantam, R.; Cogswell, M.; Parikh, D.; and Batra, D. 2016. Grad-cam: Why did you say that? visual explanations from deep networks via gradientbased localization. arXiv preprint arXiv:1610.02391.
Singh, S.; Ribeiro, M. T.; and Guestrin, C. 2016. Programs as black-box explanations. arXiv preprint arXiv:1611.07579.
Socas, M. E.; Sued, O.; Laufer, N.; Lzaro, M. E.; Mingrone, H.; Pryluka, D.; Remondegui, C.; Figueroa, M. I.; Cesar, C.; Gun, A.; Turk, G.; Bouzas, M. B.; Kavasery, R.; Krolewiecki, A.; Prez, H.; Salomn, H.; Cahn, P.; and de Seroconversin Study Group, G. A. 2011. Acute retroviral syndrome and high baseline viral load are predictors of rapid hiv progression among untreated argentinean seroconverters. Journal of the International AIDS Society 14(1):40–40.
Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence to sequence learning with neural networks. In NIPS.
Tang, W.; Hua, G.; and Wang, L. 2017. How to train a compact binary neural network with high accuracy? In AAAI.
Zazzi, M.; Incardona, F.; Rosen-Zvi, M.; Prosperi, M.; Lengauer, T.; Altmann, A.; Sonnerborg, A.; Lavee, T.; Schu¨lter, E.; and Kaiser, R. 2012. Predicting response to antiretroviral treatment by machine learning: the euresist project. Intervirology 55(2):123–127.
Zhang, Y.; Lee, J. D.; and Jordan, M. I. 2016. l1-regularized neural networks are improperly learnable in polynomial time. In ICML.
Zou, H., and Hastie, T. 2005. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 67(2):301–320.

9

Supplementary Material
A Details for Decision-Tree Training
Training decision trees with post-pruning. Our average path length function Ω(W ) for determining the complexity of a deep model with parameters W – deﬁned in the main paper in Alg. 1 – assumes that we have a robust, black-box way to train binary decision-trees called TRAINTREE given a labeled dataset {xn, yˆn}. For this we use the DecisionTree module distributed in Python’s sci-kit learn, which optimizes information gain with Gini impurity. The speciﬁc syntax we use (for reproducibility) is:
tree = DecisionTree(min_sample_count=5) tree.fit(x_train, y_train) tree = prune_tree(tree, x_valid, y_valid)
The provided keyword options force the tree to have at least 5 examples from the training set in every leaf. We found that tuning hyperparameters of the TRAINTREE subprocedure, such as the minimum size of a leaf node, to be important for making useful trees.
Generally, the runtime cost of sklearn’s ﬁtting procedure scales superlinearly with the number of examples N and linearly with the number of features F – a total complexity of O(F N log(N )). In practice, we found that with N = 1000 examples, F = 10 features, tree construction takes 15.3 microseconds.
The pruning procedure is a heuristic to create simpler trees, summarized in algorithm 2. After TRAINTREE delivers a working decision tree, we iterative propose removing each remaining leaf node, accepting the proposal if the squared prediction error on a validation set improves. This pruning removes sub-trees that don’t generalize to unseen data.

Algorithm 2 Post-pruning for training decision trees.

Require:

T : initial decision tree

ERRONVAL(·) : squared error on validation data

ERRONVAL(T )

N n=1

(T

(xn)

−

yn)2

1: procedure PRUNETREE( T , err )

2: e ← ERRONVAL(T ).

3: for node n ∈ SORTLEAFTOROOT(T.nodes) do

4:

T ← REMOVENODE(T, n)

5:

enew ← ERRONVAL(T )

6:

if enew < e then T ← T

7: Return T

Sanity check: Surrogate path length closely follow true path length. Fig. A.1 shows that our surrogate predictor Ωˆ (·) tracks the true average path length as we train the target predictor yˆ(·, W ) on several different datasets.
Sensitivity to different choices for surrogate training. In Fig. A.2, we show sample learning curves for variations of methods for approximating the average path length (also called “node count”) in a decision tree. In blue is the true value. Each of the other 3 lines use the same surrogate model: an MLP with 25 hidden nodes. Increasing its capacity too much, i.e. 100 hidden nodes, leads to overﬁtting where the surrogate is able to predict the average path length extremely well for a small number of iterations, while the performance quickly decays. With an MLP of the right capacity, four additional tricks: (1) weight augmentation, (2) random restarts with an unregularized model, (3) ﬁxed window of data, and (4) surrogate retraining greatly improve the accuracy of the average path length predictions.
Normally, if our differentiable model is a GRU, we compile examples using the GRU weights at every batch and calculate the true average path length. This dataset is used to train the surrogate model. If examples are very sparse, surrogate predictions may be unstable. Augmentation addresses this by randomly sampling weight vectors and computing the average path length to artiﬁcially create a larger dataset. Early epochs are especially problematic when it comes to lacking data. In addition to augmentation, we use random restarts to separately train unregularized GRUs (each with different weight initializations) to grow a dataset of weight vectors prior to training the regularized model.
As the GRU parameters take steps away from their initial values, our examples from those early epochs no longer describe the current state of the model. Retraining and a ﬁxed window of data address this by re-learning the surrogate function at a ﬁxed frequency using examples only from the last J epochs. In practice, both the augmentation size, the retraining frequency, and J are functions of the learning rate and the dataset size. See table B.1 for exact numbers.

10

(a) Path length estimates Ωˆ for 2D Parabola task

(b) Path length estimates Ωˆ for Signal-and-noise HMM task
Figure A.1: True average path lengths (yellow) and surrogate estimates Ωˆ (green) across many iterations of network parameter training iterations.

ground truth retraLnLng

augPentatLon retraLnLng + augPentatLon

Average 3ath Length

15 10
5

0

50

100

150

200

250

300

Epoch

Figure A.2: This ﬁgure shows the effects of weight augmentation and retraining. The blue line is the true average path length of the decision tree at each epoch. All other lines show predicted path lengths using the surrogate MLP. By randomly sampling weights and intermittently retraining the surrogate, we signiﬁcantly improve the ability of the surrogate model to track the changes in the ground truth.

11

B Experimental Protocol
See table B.1 for model hyperparameters for each dataset. For standard recurrent models such as HMM or GRU, the decision trees were trained on the input data and the predictions of the model’s output node. For our deep residual GRU-HMM, the decision trees were trained on the predictions on the GRU’s output node only. For both synthetic and real-world datasets, our surrogate to the tree loss is a multilayer perceptron with 1 hidden layer of 25 nodes. For each dataset, when we investigated several regularization strengths (λ), we initialize the model weights using the same random seed. We use the Adam algorithm (Kingma and Ba 2014) for all optimization.

Dataset

Total Num. Sequences Avg. seq. length Learning Rate Batch size Minimum Leaf Sample Post-pruned Epochs (Model) Epochs (Surrogate) Retraining Freq. J

parabola

n/a

n/a

1e-2

32

0

N

250

500

100

n/a

signal-and-noise HMM

100

50

1e-2

10

25

Y

300

1000

50

50

HIV

53 236

14

1e-3

256

1 000

Y

300

5000

25

100

SEPSIS

11 786

15

1e-3

256

1 000

Y

300

5000

25

100

TIMIT

6 303

614

1e-3

256

5 000

Y

200

5000

25

100

Table B.1: Dataset summaries and training parameters used in our experiments.

B.1 2D Parabola
Dataset generation. The training data consists of 2D input points whose two-class decision boundary is roughly shaped like a parabola. The true decision function is deﬁned by y = 5 ∗ (x − 0.5)2 + 0.4. We sampled all 200 input points xn uniformly within the unit square [0, 1] × [0, 1] and labeled those above the decision function as positive. To add randomness, we ﬂipped 10% of the points in the region near the boundary between y = 5 ∗ (x − 0.5)2 + 0.2 and y = 5 ∗ (x − 0.5)2 + 0.6.

Regularization strengths. Tested values of regularization strength parameter λ: 0.1, 0.5, 1, 5, 10, 25, 50, 75, 100, 250, 500, 750, 1 000, 2 500, 5 000, 7 500, 10 000, 25 000, 50 000, 75 000, 100 000

B.2 Signal-and-noise HMM
Dataset generation The transition and emission matrices describing the generative process used to create the signal-and-noise HMM are shown in Fig. B.1. The output yn at every timestep is created by concatenating a one-hot vector of an emitted state and the 7-dimensional binary input vector. We emphasize that to output 1, the HMM must be in state 1 and the ﬁrst input feature must be 1.

.5 .5 .5 .5 0 0 0 .5 .5 .5 .5 .5 0 0 .5 .5 .5 0 .5 0 0 .5 .5 .5 0 0 .5 0 .5 .5 .5 0 0 0 .5
(a)
.5 .5 .5 0 0 0 0 0 .5 .5 .5 0 0 0 0 0 .5 .5 .5 0 0 0 0 0 .5 .5 .5 0 0 0 0 0 .5 .5 .5
(c)

.7 .3 0 0 0 .5 .25 .25 0 0 0 .25 .5 .25 0 0 0 .25 .25 .5 0 0 0 .5 .5
(b)
.2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2 .2
(d)

Figure B.1: Emission (5 states vs 7 features) and transition probabilities for the signal HMM (a, b) and noise HMM (c, d).

Training Details. With synthetic datasets, we explore (1, 5, 6, 10, 15, 20) GRU nodes, (5, 6, 20) HMM states, and GRU-HMMs with 5 HMM states and (1, 5, 10, 15) GRU nodes.
B.3 Sepsis Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75, 100) GRU nodes, (5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75, 100) HMM states, and GRU-HMMs with (5, 10, 25, 50) HMM states and (1, 5, 10, 25, 50) GRU nodes. The input features are z-scored prior to training.
B.4 HIV Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) GRU nodes, (5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) HMM states, and GRU-HMMs with (5, 10, 25) HMM states and (1, 5, 10, 25, 50) GRU nodes.
12

B.5 TIMIT Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) GRU nodes, (5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) HMM states, and GRU-HMMs with (5, 10, 25) HMM states and (1, 5, 10, 25, 50) GRU nodes. Like Sepsis, the input features are z-scored prior to training.
C Extended Results
For signal-to-noise HMM, Sepsis, and TIMIT, we ﬁrst show expanded versions of the ﬁtness trace plots and the tree visualizations. For Sepsis and HIV, we show the additional output dimensions not in the paper.
We also include tables of the test AUC performance for our synthetic and real data sets over a vast array of parameter settings (GRU node counts, HMM state counts, regularization strengths). Consistent with the common wisdom of training deep models, we found that larger models, with regularization, tended to perform the best.
C.1 Signal-and-noise HMM: Plots

AUC (Test) AUC (Test)

(a) GRU: Signal-and-noise HMM

(b) GRUHMM: Signal-and-noise HMM

1.0 0.955
0.9 0.950
0.8

0.7

GRU (L1)

0.945

GRU (L2)

GRU-HMM (L1)

0.6

GRU (Tree)

0.940

GRU-HMM (L2)

Decision Tree

GRU-HMM (Tree)

0.50

10

20

30

40

0.9350

5 10 15 20 25 30

Average Path Length

Average Path Length

Figure C.1: Performance and complexity trade-offs using L1, L2, and Tree regularization on (a) GRU and (b) GRU-HMM performance on the Signal-and-noise HMM dataset. Note the differences in scale.

13

C.2 Signal-and-noise HMM: Tree Visualization

X[0] <= 0.5 value = [3915, 1085]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1369, 1085]
class = off

X[4] <= 0.5 value = [1246, 498]
class = off

X[4] <= 0.5 value = [123, 587]
class = on

X[6] <= 0.5 value = [920, 498]
class = off

value = [326, 0] class = off

value = [0, 587] class = on

value = [123, 0] class = off

X[5] <= 0.5 value = [759, 498]
class = off

value = [161, 0] class = off

X[11] <= 0.5 value = [606, 498]
class = off

value = [153, 0] class = off

X[8] <= 0.5 value = [430, 340]
class = off

X[1] <= 0.5 value = [176, 158]
class = off

X[7] <= 0.5 value = [200, 340]
class = on

value = [230, 0] class = off

X[2] <= 0.5 value = [83, 94]
class = on

X[2] <= 0.5 value = [93, 64]
class = off

X[12] <= 0.5 value = [170, 324]
class = on

value = [30, 16] class = off

value = [83, 0] class = off

value = [0, 94] class = on

X[10] <= 0.5 value = [43, 40]
class = off

value = [50, 24] class = off

X[9] <= 0.5 value = [66, 324]
class = on

value = [104, 0] class = off

value = [27, 28] class = on

value = [16, 12] class = off

X[10] <= 0.5 value = [31, 198]
class = on

X[10] <= 0.5 value = [35, 126]
class = on

X[1] <= 0.5 value = [31, 121]
class = on

value = [0, 77] class = on

value = [0, 99] class = on

X[1] <= 0.5 value = [35, 27]
class = off

value = [0, 78] class = on

X[2] <= 0.5 value = [31, 43]
class = on

value = [17, 18] class = on

value = [18, 9] class = off

value = [11, 23] class = on

value = [20, 20] class = off

X[0] <= 0.5 value = [3915, 1085]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1369, 1085]
class = off

X[4] <= 0.5 value = [1246, 498]
class = off

X[4] <= 0.5 value = [123, 587]
class = on

X[6] <= 0.5 value = [920, 498]
class = off

value = [326, 0] class = off

value = [0, 587] class = on

value = [123, 0] class = off

X[5] <= 0.5 value = [759, 498]
class = off

value = [161, 0] class = off

X[11] <= 0.5 value = [606, 498]
class = off

value = [153, 0] class = off

X[8] <= 0.5 value = [430, 340]
class = off

X[1] <= 0.5 value = [176, 158]
class = off

X[7] <= 0.5 value = [200, 340]
class = on

value = [230, 0] class = off

X[2] <= 0.5 value = [83, 94]
class = on

X[2] <= 0.5 value = [93, 64]
class = off

X[12] <= 0.5 value = [170, 324]
class = on

value = [30, 16] class = off

value = [83, 0] class = off

value = [0, 94] class = on

X[10] <= 0.5 value = [43, 40]
class = off

value = [50, 24] class = off

X[9] <= 0.5 value = [66, 324]
class = on

value = [104, 0] class = off

value = [27, 28] class = on

value = [16, 12] class = off

X[10] <= 0.5 value = [31, 198]
class = on

X[10] <= 0.5 value = [35, 126]
class = on

X[1] <= 0.5 value = [31, 121]
class = on

value = [0, 77] class = on

value = [0, 99] class = on

X[1] <= 0.5 value = [35, 27]
class = off

value = [0, 78] class = on

X[2] <= 0.5 value = [31, 43]
class = on

value = [17, 18] class = on

value = [18, 9] class = off

value = [11, 23] class = on

value = [20, 20] class = off

X[0] <= 0.5 value = [3897, 1103]
class = off

True

False

value = [2546, 0] class = off

X[4] <= 0.5 value = [1351, 1103]
class = off

X[3] <= 0.5 value = [902, 1103]
class = on

value = [449, 0] class = off

X[6] <= 0.5 value = [902, 516]
class = off

value = [0, 587] class = on

X[5] <= 0.5 value = [741, 516]
class = off

value = [161, 0] class = off

X[11] <= 0.5 value = [588, 516]
class = off

value = [153, 0] class = off

X[1] <= 0.5 value = [254, 516]
class = on

value = [334, 0] class = off

X[8] <= 0.5 value = [112, 280]
class = on

X[9] <= 0.5 value = [142, 236]
class = on

value = [0, 280] class = on

value = [112, 0] class = off

value = [0, 236] class = on

value = [142, 0] class = off

X[3] <= 0.5 value = [4644, 356]
class = off

True

False

value = [3532, 0] class = off

X[0] <= 0.5 value = [1112, 356]
class = off

value = [758, 0] class = off

X[4] <= 0.5 value = [354, 356]
class = on

X[11] <= 0.5 value = [231, 356]
class = on

value = [123, 0] class = off

X[7] <= 0.5 value = [82, 308]
class = on

X[12] <= 0.5 value = [149, 48]
class = off

X[9] <= 0.5 value = [45, 295]
class = on

value = [37, 13] class = off

X[10] <= 0.5 value = [82, 48]
class = off

value = [67, 0] class = off

X[1] <= 0.5 value = [19, 205]
class = on

X[8] <= 0.5 value = [26, 90]
class = on

X[2] <= 0.5 value = [31, 48]
class = on

value = [51, 0] class = off

value = [0, 108] class = on

X[12] <= 0.5 value = [19, 97]
class = on

value = [0, 75] class = on

value = [26, 15] class = off

value = [14, 31] class = on

value = [17, 17] class = off

value = [0, 83] class = on

value = [19, 14] class = off

X[3] <= 0.5 value = [4747, 253]
class = off

True

False

value = [3532, 0] class = off

X[0] <= 0.5 value = [1215, 253]
class = off

value = [758, 0] class = off

X[4] <= 0.5 value = [457, 253]
class = off

X[8] <= 0.5 value = [334, 253]
class = off

value = [123, 0] class = off

X[10] <= 0.5 value = [222, 253]
class = on

value = [112, 0] class = off

X[1] <= 0.5 value = [95, 217]
class = on

X[2] <= 0.5 value = [127, 36]
class = off

value = [0, 137] class = on

X[2] <= 0.5 value = [95, 80]
class = off

X[12] <= 0.5 value = [48, 36]
class = off

value = [79, 0] class = off

value = [0, 80] class = on

value = [95, 0] class = off

X[1] <= 0.5 value = [29, 29]
class = off

value = [19, 7] class = off

value = [13, 16] class = on

value = [16, 13] class = off

(a) GRU:0.1

X[3] <= 0.5 value = [4761, 239]
class = off

True

False

value = [3532, 0] class = off

X[0] <= 0.5 value = [1229, 239]
class = off

value = [758, 0] class = off

X[4] <= 0.5 value = [471, 239]
class = off

X[11] <= 0.5 value = [348, 239]
class = off

value = [123, 0] class = off

X[2] <= 0.5 value = [151, 239]
class = on

value = [197, 0] class = off

X[1] <= 0.5 value = [16, 186]
class = on

X[1] <= 0.5 value = [135, 53]
class = off

value = [0, 101] class = on

X[10] <= 0.5 value = [16, 85]
class = on

X[9] <= 0.5 value = [36, 53]
class = on

value = [99, 0] class = off

value = [0, 69] class = on

value = [16, 16] class = off

value = [14, 42] class = on

value = [22, 11] class = off

(b) GRU:0.1

X[3] <= 0.5 value = [4783, 217]
class = off

True

False

value = [3532, 0] class = off

X[0] <= 0.5 value = [1251, 217]
class = off

value = [758, 0] class = off

X[4] <= 0.5 value = [493, 217]
class = off

X[1] <= 0.5 value = [370, 217]
class = off

value = [123, 0] class = off

X[8] <= 0.5 value = [62, 217]
class = on

value = [308, 0] class = off

value = [0, 217] class = on

value = [62, 0] class = off

(c) GRU:1.0

X[0] <= 0.5 value = [4439, 561]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1893, 561]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [149, 561]
class = on

X[7] <= 0.5 value = [26, 561]
class = on

value = [123, 0] class = off

value = [0, 537] class = on

value = [26, 24] class = off

(d) GRU:10

X[0] <= 0.5 value = [4413, 587]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1867, 587]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [123, 587]
class = on

value = [0, 587] class = on

value = [123, 0] class = off

(e) GRU:20
value = [5000, 0] class = off

(f) GRU:100

(g) GRU::400

(h) GRU:800

(i) GRU:1 000

(j) GRU:10 000

Figure C.2: Decision trees trained under varying tree regularization strengths for GRU models on the signal-and-noise HMM dataset dataset. As the tree regularization increases, the number of nodes collapses to a single one. If we focus on (h), we see that the tree resembles the ground truth data-generating function quite closely.

14

C.3 Signal-and-noise HMM: AUCs

Model
logreg decision tree
hmm (5) hmm (20)
gru (1) gru (5) gru (6) gru (10) gru (15) gru (20) grutree (20/10.0) grutree (20/200.0) grutree (20/7 000.0) grutree (20/9 000.0) grutree (20/10 000.0) gruhmm (5/1) gruhmm (5/5) gruhmm (5/10) gruhmm (5/15) gruhmmtree (5/15/1.0) gruhmmtree (5/15/10.0) gruhmmtree (5/15/50.0) gruhmmtree (5/15/200.0) gruhmmtree (5/15/500.0) gruhmmtree (5/15/900.0) gruhmmtree (5/15/2 000.0) gruhmmtree (5/15/5 000.0) gruhmmtree (5/15/7 000.0)

AUC (Test)
0.91832 0.92050 0.93591 0.94177 0.65049 0.94812 0.94883 0.94962 0.93982 0.93368 0.94226 0.94806 0.94431 0.90555 0.82770 0.95146 0.95584 0.95773 0.94857 0.95382 0.95180 0.95258 0.95145 0.95769 0.95708 0.95648 0.95399 0.93591

Average Path Length
17.302 29.4424 25.5736 27.2784 1.8876 26.304 27.2118 28.563 30.7172 37.0844 28.1850 26.8140 22.4646 9.1127 3.4400 18.2202 27.258 30.9624 36.7188 24.115 16.883 12.573
8.926 5.231 3.942 2.694 1.896 0.000

Parameter Count
6 71 581 29 205 264 560 1 065 1 720 1 720 1 720 1 720 1 720 1 720 100 276 631 1 136 1 136 1 136 1 136 1 136 1 136 1 136 1 136 1 136 1 136

Table C.1: Performance metrics across models on the signal-and-noise HMM dataset. The parameter count is included as a measure of the model capacity.

15

C.4 Sepsis: Plots

AUC (Test) AUC (Test) AUC (Test)

(a) In-Hospital Mortality

0.7
0.6
0.5 0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree

10

20

30

Average Path Length

(b) 90-Day Mortality

0.7 0.6 0.5
0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree

5

10

15

20

Average Path Length

(c) Mechanical Ventilation

0.9

0.8

0.7
0.6
0.5 0.0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree
2.5 5.0 7.5 10.0 12.5 Average Path Length

(d) Median Vasopressor
0.8

(e) Max Vasopressor
0.8

AUC (Test) AUC (Test)

0.7
0.6
0.5 0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree

5

10 15 20 25

Average Path Length

0.7
0.6
0.5 0

GRU (L1) GRU (L2) GRU (Tree) Decision Tree

5

10 15 20 25

Average Path Length

Figure C.3: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU performance on the Sepsis dataset.

C.5 Sepsis: Tree Visualization

age <= 64.212 value = [35299, 65553] class = died_in_hosp:OFF
True
BUN <= 28.163 value = [30660, 14493] class = died_in_hosp:ON

False
BUN <= 24.153 value = [4639, 51060] class = died_in_hosp:OFF

Platelets_count <= 101.882 value = [29033, 2784]
class = died_in_hosp:ON

BUN <= 49.909 value = [1627, 11709] class = died_in_hosp:OFF

age <= 74.354 value = [4639, 19225] class = died_in_hosp:OFF

value = [0, 31835] class = died_in_hosp:OFF

age <= 51.728 value = [1427, 2784] class = died_in_hosp:OFF

value = [27606, 0] class = died_in_hosp:ON

age <= 48.95 value = [1627, 6324] class = died_in_hosp:OFF

value = [0, 5385] class = died_in_hosp:OFF

INR <= 1.437 value = [4639, 5882] class = died_in_hosp:OFF

value = [0, 13343] class = died_in_hosp:OFF

value = [1427, 569] class = died_in_hosp:ON

value = [0, 2215] class = died_in_hosp:OFF

Arterial_BE <= -0.943 value = [1627, 809]
class = died_in_hosp:ON

value = [0, 5515] class = died_in_hosp:OFF

Hb <= 9.907 value = [4639, 3299] class = died_in_hosp:ON

value = [0, 2583] class = died_in_hosp:OFF

value = [486, 514] class = died_in_hosp:OFF

value = [1141, 295] class = died_in_hosp:ON

Platelets_count <= 289.44 value = [742, 2610]
class = died_in_hosp:OFF

HR <= 94.223 value = [3897, 689] class = died_in_hosp:ON

value = [0, 2203] class = died_in_hosp:OFF

value = [742, 407] class = died_in_hosp:ON

value = [3241, 0] class = died_in_hosp:ON

value = [656, 689] class = died_in_hosp:OFF

BUN <= 45.135 value = [94394, 6458] class = mortality_90d:ON

True

False

Arterial_BE <= -4.059 value = [79992, 1309] class = mortality_90d:ON

Arterial_BE <= -3.736 value = [14402, 5149] class = mortality_90d:ON

INR <= 1.598 value = [6660, 1309] class = mortality_90d:ON

value = [73332, 0] class = mortality_90d:ON

age <= 67.861 value = [1472, 4414] class = mortality_90d:OFF

Total_bili <= 9.535 value = [12930, 735] class = mortality_90d:ON

value = [5223, 0] class = mortality_90d:ON

Arterial_BE <= -8.251 value = [1437, 1309] class = mortality_90d:ON

Arterial_BE <= -7.194 value = [1472, 1019] class = mortality_90d:ON

value = [0, 3395] class = mortality_90d:OFF

value = [12663, 0] class = mortality_90d:ON

value = [267, 735] class = mortality_90d:OFF

value = [357, 645] class = mortality_90d:OFF

value = [1080, 664] class = mortality_90d:ON

value = [423, 578] class = mortality_90d:OFF

value = [1049, 441] class = mortality_90d:ON

GCS <= 13.998 value = [14985, 85867] class = mechvent:OFF

True

False

value = [0, 67874] class = mechvent:OFF

FiO2_100 <= 37.002 value = [14985, 17993] class = mechvent:OFF

CO2_mEqL <= 31.131 value = [13112, 599] class = mechvent:ON

FiO2_100 <= 46.663 value = [1873, 17394] class = mechvent:OFF

value = [12674, 0] class = mechvent:ON

value = [438, 599] class = mechvent:OFF

RR <= 19.136 value = [1873, 5146] class = mechvent:OFF

value = [0, 12248] class = mechvent:OFF

value = [0, 2969] class = mechvent:OFF

CO2_mEqL <= 27.007 value = [1873, 2177] class = mechvent:OFF

paO2 <= 112.252 value = [1330, 1185] class = mechvent:ON

value = [543, 992] class = mechvent:OFF

value = [885, 541] class = mechvent:ON

value = [445, 644] class = mechvent:OFF

Arterial_BE <= -5.098 value = [98690, 2162] class = median_dose_vaso:ON

True

False

SysBP <= 110.75 value = [7456, 2162] class = median_dose_vaso:ON

value = [91234, 0] class = median_dose_vaso:ON

GCS <= 11.867 value = [2750, 2162] class = median_dose_vaso:ON

value = [4706, 0] class = median_dose_vaso:ON

PAWmean <= 12.426 value = [1355, 1772] class = median_dose_vaso:OFF

value = [1395, 390] class = median_dose_vaso:ON

value = [956, 750] class = median_dose_vaso:ON

value = [399, 1022] class = median_dose_vaso:OFF

Arterial_BE <= -5.098 value = [99243, 1609] class = max_dose_vaso:ON

True

False

SysBP <= 110.75 value = [8009, 1609] class = max_dose_vaso:ON

value = [91234, 0] class = max_dose_vaso:ON

GCS <= 10.993 value = [3303, 1609] class = max_dose_vaso:ON

value = [4706, 0] class = max_dose_vaso:ON

WBC_count <= 13.128 value = [1160, 1609]
class = max_dose_vaso:OFF

value = [2143, 0] class = max_dose_vaso:ON

value = [745, 585] class = max_dose_vaso:ON

value = [415, 1024] class = max_dose_vaso:OFF

(a) In-Hospital Mortality (b) 90-Day Mortality (c) Mechanical Ventilation (d) Median Vasopressor (e) Max Vasopressor Figure C.4: Decision trees trained using λ = 800.0 for a GRU model using Sepsis. The 5 output dimensions are jointly trained.

16

C.6 Sepsis: AUCs

Model
logreg decision tree
hmm (5) hmm (10) hmm (15) hmm (20) hmm (25) hmm (30) hmm (35) hmm (50) hmm (75) hmm (100)
gru (1) gru (5) gru (10) gru (15) gru (20) gru (25) gru (30) gru (35) gru (50) gru (75) gru (100) grutree (100/0.01) grutree (100/1.0) grutree (100/8.0) grutree (100/20.0) grutree (100/70.0) grutree (100/300.0) grutree (100/2 000.0) grutree (100/5 000.0) grutree (100/7 000.0) grutree (100/8 000.0) gruhmm (1/5) gruhmm (1/10) gruhmm (1/25) gruhmm (1/50) gruhmm (5/5) gruhmm (5/10) gruhmm (5/25) gruhmm (5/50) gruhmm (10/5) gruhmm (10/10) gruhmm (10/25) gruhmm (10/50) gruhmm (25/5) gruhmm (25/10) gruhmm (25/25) gruhmm (25/50) gruhmm (50/5) gruhmm (50/10) gruhmm (50/25) gruhmm (50/50) gruhmmtree (50/50/0.5) gruhmmtree (50/50/20.0) gruhmmtree (50/50/50.0) gruhmmtree (50/50/200.0 gruhmmtree (50/50/300.0) gruhmmtree (50/50/600.0 gruhmmtree (50/50/1 000.0) gruhmmtree (50/50/3 000.0) gruhmmtree (50/50/4 000.0) gruhmmtree (50/50/7 000.0) gruhmmtree (50/50/9 000.0)

In-Hospital
Mortality
0.6980 0.7017 0.7128 0.7227 0.7216 0.7233 0.7147 0.7164 0.7177 0.7267 0.7254 0.7294 0.3897 0.7357 0.7488 0.7529 0.7535 0.7578 0.7602 0.7522 0.7431 0.7408 0.7325 0.7276 0.7147 0.7232 0.7123 0.7360 0.7210 0.7230 0.6546 0.6063 0.5298 0.4222 0.4007 0.4019 0.3999 0.7430 0.7408 0.7365 0.7222 0.7468 0.7490 0.7422 0.7254 0.7580 0.7592 0.7525 0.7604 0.7655 0.7648 0.7600 0.7412 0.7432 0.7435 0.7384 0.747 0.7539 0.7435 0.7575 0.7396 0.7432 0.7308 0.7132

90-Day
Mortality
0.6986 0.7016 0.7095 0.7297 0.7282 0.7350 0.7321 0.7297 0.7237 0.7357 0.7361 0.7354 0.6400 0.7296 0.7445 0.7450 0.7497 0.7486 0.7508 0.7483 0.7390 0.7239 0.7273 0.7314 0.7040 0.7203 0.7085 0.7376 0.7197 0.7167 0.6552 0.6554 0.5242 0.6472 0.6295 0.6207 0.6162 0.7372 0.7320 0.7279 0.7107 0.7467 0.7478 0.7407 0.7221 0.7568 0.7563 0.7508 0.7583 0.7592 0.7568 0.7555 0.7373 0.7492 0.747 0.7548 0.7502 0.7623 0.7453 0.7502 0.7484 0.7511 0.7477 0.7319

Mechanical Ventilation
0.8242 0.8509 0.6979 0.8237 0.8188 0.8218 0.8089 0.8099 0.8095 0.8373 0.8059 0.8129 0.4761 0.8795 0.8892 0.8912 0.8887 0.8902 0.8927 0.8900 0.8895 0.8837 0.8781 0.8776 0.8741 0.8763 0.8733 0.8813 0.8681 0.8335 0.6752 0.6565 0.5025 0.4678 0.4730 0.4773 0.4772 0.8798 0.8819 0.8776 0.8660 0.8949 0.8958 0.8916 0.8824 0.8941 0.8945 0.8912 0.8954 0.9006 0.9003 0.8981 0.8910 0.879 0.8826 0.8914 0.8767 0.8942 0.8821 0.8739 0.8926 0.8915 0.8813 0.8261

Median Vasopressor
0.7392 0.7439 0.7295 0.7409 0.7346 0.7371 0.7313 0.7316 0.7201 0.7335 0.7434 0.7408 0.7414 0.7866 0.7983 0.8020 0.8018 0.8113 0.8063 0.8095 0.8054 0.8006 0.7977 0.7873 0.7812 0.7845 0.7813 0.7988 0.7676 0.7616 0.6668 0.6230 0.5026 0.7478 0.7418 0.7353 0.7120 0.8009 0.7991 0.7955 0.7814 0.8098 0.8098 0.8055 0.7903 0.8236 0.8225 0.8186 0.8106 0.8228 0.8220 0.8205 0.8056 0.7854 0.7914 0.7922 0.7832 0.8092 0.7909 0.7882 0.8013 0.802 0.7881 0.7301

Max Vasopressor
0.7392 0.7427 0.7290 0.7405 0.7341 0.7364 0.7310 0.7311 0.7195 0.7328 0.7430 0.7403 0.7411 0.7862 0.7979 0.8021 0.8017 0.8114 0.8061 0.8091 0.8051 0.8000 0.7975 0.7867 0.7810 0.7840 0.7813 0.7986 0.7678 0.7619 0.6530 0.6138 0.5057 0.7477 0.7419 0.7352 0.7121 0.8006 0.7988 0.7952 0.7811 0.8097 0.8096 0.8054 0.7903 0.8235 0.8225 0.8184 0.8103 0.8226 0.8219 0.8203 0.8055 0.7849 0.7906 0.7918 0.7824 0.8091 0.7905 0.7873 0.8011 0.8024 0.7882 0.7299

Total Average
Path Length
32.489 76.242 35.125 57.629 61.832 62.353 63.415 65.164 65.474 66.317 72.553 80.415 31.816 45.395 58.102 61.025 61.214 62.029 72.854 74.091 76.543 87.422 94.161 91.797 82.019 73.767 65.035 61.012 54.177 48.206 26.085 20.214 13.383 41.583 61.041 65.955 70.534 47.639 63.627 68.215 71.572 50.902 63.522 70.919 71.297 51.794 64.223 72.480 79.127 64.229 69.281 85.503 101.637 84.188 77.815 71.719 69.715
66.9 63.703 60.949 54.751 44.868 27.836
0.0

Parameter Count
180 -
405 860 1 365 1 920 2 525 3 180 3 885 6 300 11 325 17 600 117 645 1 440 2 385 3 480 4 725 6 120 7 665 13 200 25 425 41 400 41 400 41 400 41 400 41 400 41 400 41 400 41 400 41 400 41 400 41 400 722 1 517 4 802 13 277 1 050 1 845 5 130 13 605 1 505 2 300 5 585 14 060 3 170 3 965 7 250 11 025 6 945 7 740 11 025 19 500 19 500 19 500 19 500 19 500 19 500 19 500 19 500 19 500 19 500 19 500 19 500

Table C.2: Performance metrics for multi-dimensional classiﬁcation on a held-out portion of the Sepsis dataset. Total Average Path Length refers to the summed average path lengths across the 5 output dimensions. Refer to Fig. C.3 for average-path-lengths split across dimensions.

17

AUC (Test) AUC (Test) AUC (Test)

C.7 HIV:Plots

(a) Therapy Success

0.75

0.70

0.65

0.60

GRU(L1)

GRU(L2)

0.55

GRU(Tree)

Decision Tree

0.50

15

20

25

30

Average Path Length

(b) CD4+ ≤ 200 cells/ml

0.70

0.65

GRU (L1) 0.60
GRU (L2)

GRU (Tree)

0.55

Decision Tree

10.0 12.5 15.0 17.5 20.0 Average Path Length

(c) Adherence
0.8

0.7

GRU (L1)

0.6

GRU (L2)

GRU (Tree)

Decision Tree

15.0 17.5 20.0 22.5 25.0 27.5 Average Path Length

(d) Mortality

(e) Onset of AIDS

AUC (Test) AUC (Test)

0.85 0.58
0.80

GRUHMM (L1)

0.56

0.75

GRUHMM (L2)

GRUHMM (Tree)

0.70

Decision Tree

0.54

10.0 12.5 15.0 17.5 20.0 22.5 Average Path Length

GRU (L1) GRU (L2) GRU (Tree) Decision Tree
4.0 4.5 5.0 5.5 6.0 Average Path Length

Figure C.5: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU for the HIV dataset. The 5 outputs shown here were trained jointly.

18

C.8 HIV: AUCs

Model
logreg decision tree
hmm (5) hmm (10) hmm (25) hmm (50) hmm (75) hmm (100)
gru (5) gru (25) gru (50) gru (75) gru (100) grutree (100/0.01) grutree (100/1.0) grutree (100/20.0) grutree (100/70.0) grutree (100/300.0) grutree (100/2 000.0) grutree (100/5 000.0) grutree (100/7 000.0) grutree (100/8 000.0) gruhmm (5/5) gruhmm (5/10) gruhmm (5/25) gruhmm (5/50) gruhmm (10/5) gruhmm (10/10) gruhmm (10/25) gruhmm (10/50) gruhmm (25/10) gruhmm (25/25) gruhmm (25/50) gruhmm (50/10) gruhmm (50/25) gruhmm (50/50) gruhmmtree (50/50/0.5) gruhmmtree (50/50/50.0) gruhmmtree (50/50/200.0 gruhmmtree (50/50/600.0 gruhmmtree (50/50/1 000.0) gruhmmtree (50/50/4 000.0) gruhmmtree (50/50/7 000.0)

Poor Adherence
0.6884 0.7100 0.7106 0.7287 0.7243 0.7181 0.7244 0.7261 0.6457 0.7516 0.7011 0.7623 0.7340 0.7176 0.7134 0.7157 0.7485 0.7251 0.7030 0.6549 0.6167 0.5874 0.6430 0.6708 0.6951 0.6810 0.7018 0.7190 0.7264 0.7570 0.7462 0.7435 0.7484 0.7437 0.7380 0.7317 0.7432 0.7426 0.7461 0.7467 0.7375 0.7242 0.7280

Mortality
0.7031 0.7601 0.7611 0.7627 0.7627 0.7639 0.7661 0.7657 0.6814 0.7986 0.8290 0.8514 0.8216 0.7948 0.7997 0.8066 0.8210 0.8178 0.8169 0.7582 0.7524 0.7412 0.6647 0.6720 0.6981 0.7002 0.7147 0.7378 0.7457 0.7522 0.7861 0.8102 0.7714 0.7668 0.7557 0.7684 0.7692 0.8152 0.8308 0.8820 0.8951 0.8461 0.8462

CD4+ Count ≤ 200
0.5741 0.5937 0.6012 0.6237 0.6327 0.6412 0.6294 0.6287 0.6695 0.7073 0.6995 0.7117 0.6981 0.7046 0.7138 0.7216 0.7413 0.7264 0.6342 0.6142 0.5740 0.5003 0.5418 0.5879 0.6476 0.6760 0.7049 0.7136 0.7217 0.7224 0.7152 0.7425 0.7501 0.7813 0.7824 0.7920 0.8790 0.8914 0.8767 0.8821 0.8739 0.8515 0.8313

Therapy
Success
0.6092 0.6286 0.6265 0.6409 0.6384 0.6370 0.6518 0.6524 0.6834 0.6991 0.7054 0.7490 0.7235 0.6803 0.6892 0.7114 0.7060 0.6746 0.6627 0.6352 0.5634 0.5027 0.6479 0.6517 0.6955 0.7114 0.7208 0.7578 0.7951 0.8234 0.8217 0.8186 0.8006 0.8260 0.8215 0.8007 0.7804 0.7979 0.8032 0.8293 0.7882 0.8030 0.7484

Total Average
Path Length
38.942 62.150 41.864 46.309 56.159 69.014 70.476 71.159 58.347 60.072 67.513 64.870 67.183 91.020 86.774 76.025 68.952 54.058 49.839 23.895 15.283 7.391 67.619 72.137 68.200 71.518 64.852 73.252 70.884 69.726 68.241 79.261 76.174 70.081 88.617 97.864 73.168 67.729 59.025 52.128 48.247 14.868 1.836

Parameter Count
1155 -
865 1780 4825 10900 18225 26800 1310 8050 19850 35400 54700 54700 54700 54700 54700 54700 54700 54700 54700 54700 2175 3090 6135 12210 3635 4550 7595 13670 9830 12875 18950 21630 24675 30750 30750 30750 30750 30750 30750 30750 30750

Table C.3: Performance metrics for multi-dimensional classiﬁcation on a held-out portion of the HIV dataset. Total Average Path Length refers to the summed average path lengths across the output dimensions.

19

C.9 TIMIT:Plots/Tree Visualization

AUC (Test)

1.0

0.9

0.8

0.7

GRU (L1)

GRU (L2)

0.6

GRU (Tree)

Decision Tree

0.5

20

40

60

Average path Length

(a) TIMIT Stop Phonemes

MFCC 2 <= 1.025 value = [2080661, 189997]
class = Non-Stop
True
MFCC 2 derivative <= 2.127 value = [1766114, 53937] class = Non-Stop

False
MFCC 1 derivative <= -0.331 value = [314547, 136060] class = Non-Stop

MFCC 2 derivative <= -1.662 value = [1742321, 28522] class = Non-Stop

Energy <= -0.456 value = [23793, 25415]
class = Stop

MFCC 4 <= 0.245 value = [53519, 83779]
class = Stop

MFCC 3 derivative <= -0.878 value = [261028, 52281] class = Non-Stop

MFCC 4 derivative <= -1.146 value = [68837, 23291] class = Non-Stop

Energy <= -0.565 value = [1673484, 5231]
class = Non-Stop

value = [0, 21347] class = Stop

MFCC 6 derivative <= 0.812 value = [23793, 4068] class = Non-Stop

value = [28890, 0] class = Non-Stop

MFCC 3 derivative <= -0.071 value = [24629, 83779] class = Stop

Energy <= -0.603 value = [4078, 26582]
class = Stop

MFCC 4 <= 0.414 value = [256950, 25699]
class = Non-Stop

MFCC 6 derivative <= -0.627 value = [7141, 23291] class = Stop

value = [61696, 0] class = Non-Stop

MFCC 2 derivative <= 1.366 value = [382910, 5231] class = Non-Stop

value = [1290574, 0] class = Non-Stop

value = [19761, 0] class = Non-Stop

value = [4032, 4068] class = Stop

value = [0, 24726] class = Stop

MFCC 1 derivative <= -0.644 value = [24629, 59053] class = Stop

value = [0, 24646] class = Stop

value = [4078, 1936] class = Non-Stop

value = [80106, 0] class = Non-Stop

Energy derivative <= -0.014 value = [176844, 25699] class = Non-Stop

value = [0, 19829] class = Stop

value = [7141, 3462] class = Non-Stop

value = [364646, 0] class = Non-Stop

MFCC 6 derivative <= 0.784 value = [18264, 5231] class = Non-Stop

Energy <= -0.645 value = [3557, 49725]
class = Stop

MFCC 2 <= 1.325 value = [21072, 9328]
class = Non-Stop

MFCC 2 <= 1.402 value = [16519, 17934]
class = Stop

MFCC 2 derivative <= -0.737 value = [160325, 7765] class = Non-Stop

value = [14320, 0] class = Non-Stop

value = [3944, 5231] class = Stop

value = [0, 46482] class = Stop

value = [3557, 3243] class = Non-Stop

value = [14043, 0] class = Non-Stop

Energy derivative = -0.023 value = [7029, 9328] class = Stop

MFCC 1 <= 0.366 value = [16519, 3453]
class = Non-Stop

value = [0, 14481] class = Stop

MFCC 1 <= 0.421 value = [8879, 7765]
class = Non-Stop

value = [151446, 0] class = Non-Stop

value = [1886, 4533] class = Stop

value = [5143, 4795] class = Non-Stop

value = [2628, 3453] class = Stop

value = [13891, 0] class = Non-Stop

value = [4584, 6000] class = Stop

value = [4294, 1765] class = Non-Stop

(b) GRU:500
Figure C.6: (a) Performance and complexity trade-offs using L1, L2, and Tree regularization for GRU models on TIMIT. (b) Decision tree trained using λ = 500.0 tree regularization on GRU.

20

C.10 TIMIT:AUCs

Model
logreg decision tree
hmm (5) hmm (10) hmm (25) hmm (50) hmm (75)
gru (1) gru (5) gru (10) gru (25) gru (50) gru (75) gruhmm (1/5) gruhmm (1/10) gruhmm (1/25) gruhmm (5/5) gruhmm (5/10) gruhmm (5/25) gruhmm (10/5) gruhmm (10/10) gruhmm (10/25) gruhmm (25/5) gruhmm (25/10) gruhmm (25/25) gruhmm (50/5) gruhmm (50/10) gruhmm (50/25) grutree (75/0.01) grutree (75/0.1) grutree (75/0.5) grutree (75/2.0) grutree (75/5.0) grutree (75/10.0) grutree (75/100.0) grutree (75/500.0) grutree (75/700.0) grutree (75/800.0) grutree (75/1 000.0) grutree (75/6 000.0) grutree (75/7 000.0) gruhmmtree (50/25/0.1) gruhmmtree (50/25/1.0) gruhmmtree (50/25/6.0) gruhmmtree (50/25/20.0) gruhmmtree (50/25/30.0) gruhmmtree (50/25/70.0) gruhmmtree (50/25/100.0) gruhmmtree (50/25/500.0) gruhmmtree (50/25/700.0) gruhmmtree (50/25/1 000.0) gruhmmtree (50/25/3 000.0) gruhmmtree (50/25/4 000.0) gruhmmtree (50/25/7 000.0) gruhmmtree (50/25/9 000.0) gruhmmtree (50/25/10 000.0)

AUC
0.7747 0.8668 0.8900 0.8981 0.9129 0.9189 0.9251 0.9169 0.9451 0.9509 0.9547 0.9578 0.9620 0.9419 0.9535 0.9636 0.9569 0.9575 0.9603 0.9626 0.9641 0.9651 0.9635 0.9657 0.9663 0.9676 0.9679 0.9685 0.9517 0.9466 0.9367 0.9311 0.9302 0.9288 0.8911 0.8998 0.8628 0.7471 0.7082 0.5441 0.5088 0.9507 0.9465 0.9515 0.9449 0.9482 0.9460 0.9470 0.9401 0.9352 0.9390 0.9280 0.9311 0.9290 0.9134 0.9125

Average Path Length
23.460 59.2061 51.911 56.273 57.602 63.752 71.473 42.602 49.275 60.079 62.051 64.957 68.998 54.9723 53.5642 57.3290 55.9531 57.6199 59.9925 57.0652 60.7877 61.0018 57.5288 60.5212 65.0161 62.2378 65.1191 67.4301 66.2801 62.4316 60.8764 58.3659 55.7588 46.6616 40.1123 28.4240 25.136 22.6671 17.1523 11.1108 8.9910 69.1110 67.5773 65.1494 64.0072 62.5406 58.0111 51.2417 42.1882 40.1281 38.0072 25.9120 21.7170 10.1122 1.0563 0.0000

Parameter Count
27 295 640 1 975 5 200 9 675 86 490 1 130 3 950 11 650 23 100 381 726 2601 785 1 130 2 465 1 425 1 770 3 105 4 245 4 590 5 925 11 945 12 290 13 625 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 23 100 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625 13 625

Table C.4: Performance metrics across models on a held-out portion of the TIMIT dataset.

21

D GRU-HMM: Deep Residual Timeseries Model
Hidden Markov Model For our purposes, Hidden Markov Models (HMMs) can be viewed as stochastic RNNs which can be interpreted as probabilistic generative models. In this work, we consider an HMM to generate a latent variable sequence z = [z1, . . . zT ] via a Markov chain, where each latent indicates one of K possible discrete states: zt ∈ {1, ..., K}. This state sequence is then used to jointly produce the “data” xt and “outcomes” yt observed at each timestep. The joint distribution over z, x, y factorizes as:

T

p(z, y) = π0(z0) p(zt|zt−1, A) · p(xt|zt, φ)Bern(yt|σ( wkδk(zt))),

(6)

t=1

k

where A is a transition matrix such that Ai,j = Pr(zt = i|zt−1 = j), π0 = p(z0) is the initial state distribution, {φk}Kk=1 are the emission parameters that generate data. We can then apply the same objective as above for training.

GRU-HMM: Modeling the residuals of an HMM. We now consider an additional model, the GRU-HMM, designed for interpretability. The idea is to use a GRU to to model the residual errors when predicting the binary target via the HMM belief states. We can further penalize the complexity of the GRU predictions via our tree regularization, so that higher-quality predictions do not come at the price of a much less interpretable model.

ht

yt

λ

h t-1

sigm

1-

rt
sigm

zt
sigm

~h t
tanh

…

st-1

st

st+1

…

…

xt-1

xt

xt+1

…

x t-1

Figure D.1: Deep residual model: GRU-HMM. The orange triangle indicates the output used in surrogate training for tree regularization.

We train the deep residual model on the same suite of synthetic and real world datasets. See Tables C.1, C.2, C.4 for a comparison of GRU-HMM with vanilla GRU and HMM models under different regularization and expressiveness parameters. We can see that across the datasets, deep residual models perform around 1% better than their vanilla equivalents with roughly the same number of model parameters.
By nature of being a residual model, decision trees were trained only on the GRU output node, leaving the HMM unconstrained. See Figure D.1 for a pictoral representation. Similar to what we did for GRU models, ﬁgures C.1b, D.2 compare model performance as the λ parameter for L1, L2, and Tree regularization increase. We can see a similar albeit less pronounced effect where Tree regularization dominates other methods in low node count regions. It is important to notice the range of the AUC axis in these ﬁgures, where the worst the residual model can performance is the HMM-only AUC. Figure D.3 show the regularized trees produced by the GRU-HMM. Although they share some structure with Figure C.4, there are important distinctions that encourage us to conclude that the GRU in a residual models performs a different role than when trained alone.

22

D.1 GRU-HMM: Sepsis Plots

AUC (Test) AUC (Test) AUC (Test)

(a) In-Hospital Mortality

0.75 0.74 0.73 0.72
0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

10

20

30

Average Path Length

(b) 90-Day Mortality

0.76

0.75

0.74
0.73 0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

5

10

15

20

Average Path Length

(c) Mechanical Ventilation

0.90 0.88 0.86 0.84 0.82
0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

2

4

6

8 10

Average Path Length

(d) Median Vasopressor

(e) Max Vasopressor

AUC (Test) AUC (Test)

0.80 0.78 0.76 0.74
0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

5

10 15 20 25

Average Path Length

0.80 0.78 0.76 0.74
0

GRU-HMM (L1) GRU-HMM (L2) GRU-HMM (Tree)

5

10

15

20

Average Path Length

Figure D.2: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU-HMM performance on the Sepsis dataset.

D.2 GRU-HMM: Sepsis Tree Visualization

age <= 69.718 value = [67747, 33105] class = died_in_hosp:ON
True
BUN <= 22.133 value = [52415, 4570] class = died_in_hosp:ON

False
BUN <= 31.111 value = [15332, 28535] class = died_in_hosp:OFF

value = [32484, 0] class = died_in_hosp:ON

INR <= 1.896 value = [19931, 4570] class = died_in_hosp:ON

age <= 77.443 value = [15332, 9641] class = died_in_hosp:ON

value = [0, 18894] class = died_in_hosp:OFF

age <= 57.721 value = [18980, 734] class = died_in_hosp:ON

age <= 52.295 value = [951, 3836] class = died_in_hosp:OFF

PTT <= 41.791 value = [8645, 1213] class = died_in_hosp:ON

PTT <= 30.663 value = [6687, 8428] class = died_in_hosp:OFF

value = [8998, 0] class = died_in_hosp:ON

WBC_count <= 22.659 value = [9982, 734]
class = died_in_hosp:ON

value = [951, 620] class = died_in_hosp:ON

value = [0, 3216] class = died_in_hosp:OFF

value = [7785, 0] class = died_in_hosp:ON

INR <= 1.446 value = [860, 1213] class = died_in_hosp:OFF

Calcium <= 8.363 value = [4565, 1988] class = died_in_hosp:ON

Sodium <= 139.973 value = [2122, 6440] class = died_in_hosp:OFF

value = [9707, 0] class = died_in_hosp:ON

value = [275, 734] class = died_in_hosp:OFF

value = [522, 494] class = died_in_hosp:ON

value = [338, 719] class = died_in_hosp:OFF

Sodium <= 139.612 value = [1680, 1988] class = died_in_hosp:OFF

value = [2885, 0] class = died_in_hosp:ON

Arterial_BE <= -0.994 value = [2122, 2658] class = died_in_hosp:OFF

value = [0, 3782] class = died_in_hosp:OFF

value = [1087, 841] class = died_in_hosp:ON

value = [593, 1147] class = died_in_hosp:OFF

value = [381, 1081] class = died_in_hosp:OFF

Arterial_pH <= 7.41 value = [1741, 1577] class = died_in_hosp:ON

value = [589, 821] class = died_in_hosp:OFF

value = [1152, 756] class = died_in_hosp:ON

BUN <= 35.563 value = [87796, 13056] class = mortality_90d:ON

True

False

age <= 74.873 value = [68699, 2792] class = mortality_90d:ON

age <= 68.597 value = [19097, 10264] class = mortality_90d:ON

value = [50800, 0] class = mortality_90d:ON

HCO3 <= 21.996 value = [17899, 2792] class = mortality_90d:ON

INR <= 1.706 value = [11194, 1634] class = mortality_90d:ON

PTT <= 31.04 value = [7903, 8630] class = mortality_90d:OFF

WBC_count <= 13.352 value = [2489, 2060]
class = mortality_90d:ON

WBC_count <= 19.981 value = [15410, 732]
class = mortality_90d:ON

value = [9400, 0] class = mortality_90d:ON

SysBP <= 112.842 value = [1794, 1634] class = mortality_90d:ON

WBC_count <= 17.45 value = [4372, 2038] class = mortality_90d:ON

WBC_count <= 14.916 value = [3531, 6592]
class = mortality_90d:OFF

value = [2489, 0] class = mortality_90d:ON

value = [0, 2060] class = mortality_90d:OFF

value = [14746, 0] class = mortality_90d:ON

value = [664, 732] class = mortality_90d:OFF

value = [744, 1136] class = mortality_90d:OFF

value = [1050, 498] class = mortality_90d:ON

PAWmean <= 9.83 value = [3784, 1132] class = mortality_90d:ON

value = [588, 906] class = mortality_90d:OFF

BUN <= 72.07 value = [3531, 3094] class = mortality_90d:ON

value = [0, 3498] class = mortality_90d:OFF

value = [2124, 0] class = mortality_90d:ON

SysBP <= 114.366 value = [1660, 1132] class = mortality_90d:ON

Arterial_pH <= 7.361 value = [3276, 1864] class = mortality_90d:ON

value = [255, 1230] class = mortality_90d:OFF

value = [573, 612] class = mortality_90d:OFF

value = [1087, 520] class = mortality_90d:ON

value = [612, 1174] class = mortality_90d:OFF

INR <= 1.683 value = [2664, 690] class = mortality_90d:ON

value = [2109, 0] class = mortality_90d:ON

value = [555, 690] class = mortality_90d:OFF

GCS <= 13.999 value = [20205, 80647] class = mechvent:OFF

True

False

GCS <= 11.98 value = [2026, 65848] class = mentvent:OFF

FiO2_100 <= 36.012 value = [18179, 14799] class = mechvent:ON

value = [0, 56767] class = mechvent:OFF

FiO2_100 <= 36.065 value = [2026, 9081] class = mechvent:OFF

value = [13502, 0] class = mechvent:ON

CO2_mEqL <= 23.03 value = [4677, 14799] class = mechvent:OFF

value = [2026, 0] class = mechvent:ON

value = [0, 9081] class = mechvent:OFF

paO2 <= 114.951 value = [3694, 2015] class = mechvent:ON

FiO2_100 <= 44.082 value = [983, 12784] class = mechvent:OFF

value = [3694, 0] class = mechvent:ON

value = [0, 2015] class = mechvent:OFF

SpO2 <= 96.803 value = [983, 3729] class = mechvent:OFF

value = [0, 9055] class = mechvent:OFF

value = [983, 965] class = mechvent:ON

value = [0, 2764] class = mechvent:OFF

Total_bili <= 9.574 value = [96006, 4846] class = median_dose_vaso:ON

True

False

SysBP <= 109.952 value = [95031, 2153] class = median_dose_vaso:ON

SysBP <= 115.002 value = [975, 2693] class = median_dose_vaso:OFF

Arterial_BE <= -3.222 value = [31191, 2153] class = median_dose_vaso:ON

value = [63840, 0] class = median_dose_vaso:ON

value = [0, 2171] class = median_dose_vaso:OFF

value = [975, 522] class = median_dose_vaso:ON

PTT <= 46.332 value = [5138, 2153] class = median_dose_vaso:ON

value = [26053, 0] class = median_dose_vaso:ON

Hb <= 10.206 value = [4420, 1040] class = median_dose_vaso:ON

value = [718, 1113] class = median_dose_vaso:OFF

value = [2925, 0] class = median_dose_vaso:ON

PAWmean <= 11.874 value = [1495, 1040] class = median_dose_vaso:ON

value = [1022, 422] class = median_dose_vaso:ON

value = [473, 598] class = median_dose_vaso:OFF

Total_bili <= 9.58 value = [97028, 3824] class = max_dose_vaso:ON

True

False

SysBP <= 109.952 value = [96056, 1129] class = max_dose_vaso:ON

SysBP <= 115.002 value = [972, 2695] class = max_dose_vaso:OFF

Arterial_BE <= -3.222 value = [32215, 1129] class = max_dose_vaso:ON

value = [63841, 0] class = max_dose_vaso:ON

value = [0, 2171] class = max_dose_vaso:OFF

value = [972, 524] class = max_dose_vaso:ON

PTT <= 46.235 value = [6162, 1129] class = max_dose_vaso:ON

value = [26053, 0] class = max_dose_vaso:ON

value = [5450, 0] class = max_dose_vaso:ON

value = [712, 1129] class = max_dose_vaso:OFF

(a) In-Hospital Mortality (b) 90-Day Mortality (c) Mechanical Ventilation (d) Median Vasopressor (e) Max Vasopressor Figure D.3: Decision trees trained using Tree regularization (λ = 2000.0) from GRU-HMM predictions on the Sepsis dataset.

23

D.3 GRU-HMM: HIV Plots/Tree Visualization

Baseline CD4 <= 15486.29 value = [21797, 52088] class = CD4 < 200: OFF
True
Baseline VL <= 359.17 value = [7653, 5088] class = CD4 < 200: ON

Baseline CD4 <= 45000.07 value = [14144, 47000] class=CD4 < 200:OFF

Baseline VL <= 201.6 value = [4389, 4657] class=CD4 < 200:OFF

Baseline VL <= 45639.51 value = [3624, 431] class=CD4 < 200:ON

Baseline VL <= 0.5 value = [6402, 26851] class=CD4 < 200:OFF

MU_RT210 <= 0.5 value = [7742, 20149] class=CD4 < 200:OFF

MU_PR69 <= 0.5 value = [2846, 4111] class=CD4 < 200:OFF

HIST AZT <= 0.5 value = [1543, 546] class=CD4 < 200:ON

HIST EFV <= 0.5 value = [2116, 431] class=CD4 < 200:ON

value = [1148, 0] class=CD4 < 200:ON

value = [3699, 6318] class=CD4 < 200:OFF

value = [2703, 20533] class=CD4 < 200:OFF

value = [3574, 16742] class=CD4 < 200:OFF

MU_RT181 <= 0.5 value = [4168, 3407] class=CD4 < 200:OFF

value = [0, 3094] class=CD4 < 200:OFF

value = [2846, 1017] class=CD4 < 200:OFF

value = [0, 546] class=CD4 < 200:ON

value = [1543, 0] class=CD4 < 200:ON

value = [1435, 246] class=CD4 < 200:ON

value = [681, 185] class=CD4 < 200:ON

value = [2687, 2806] class=CD4 < 200:OFF

value = [1481, 601] class=CD4 < 200:OFF

Baseline CD4 <= 15486.29 value = [21797, 52088] class = CD4 < 200: OFF
True

Baseline VL <= 359.17 value = [7653, 5088] class = CD4 < 200: ON

Baseline CD4 <= 45000.07 value = [14144, 47000] class=CD4 < 200:OFF

Baseline VL <= 201.6 value = [4389, 4657] class=CD4 < 200:OFF

Baseline VL <= 45639.51 value = [3624, 431] class=CD4 < 200:ON

Baseline VL <= 0.5 value = [6402, 26851] class=CD4 < 200:OFF

MU_RT210 <= 0.5 value = [7742, 20149] class=CD4 < 200:OFF

MU_PR69 <= 0.5 value = [2846, 4111] class=CD4 < 200:OFF

value = [1543, 546] class=CD4 < 200:ON

HIST EFV <= 0.5 value = [2116, 431] class=CD4 < 200:ON

value = [1148, 0] class=CD4 < 200:ON

value = [3699, 6318] class=CD4 < 200:OFF

value = [2703, 20533] class=CD4 < 200:OFF

value = [3574, 16742] class=CD4 < 200:OFF

value = [4168, 3407] class=CD4 < 200:OFF

value = [0, 3094] class=CD4 < 200:OFF

value = [2846, 1017] class=CD4 < 200:OFF

value = [1435, 246] class=CD4 < 200:ON

value = [681, 185] class=CD4 < 200:ON

(a) GRU-HMM: CD4+ ≤ 200 cells/ml

(b) GRU-HMM: CD4+ ≤ 200 cells/ml

Figure D.4: HIV task: Study of different regularization techniques for GRU-HMM model with 75 GRU nodes and 25 HMM states, trained to predict whether CD4+ ≤ 200 cells/ml. (a) Example decision tree for λ = 1000.0. (b) Example decision tree for λ = 3000.0. The tree in (b) is slightly smaller than the tree in (a) as a result of the regularisation.

D.4 GRU-HMM: TIMIT Plots/Tree Visualization

A8C (THst)

0.95 0.94 0.93 0.92
0

G58-H00 (L1) G58-H00 (L2) G58-H00 (TUHH)

20

40

60

80

AvHUagH 3ath LHngth

MFCC 2 <= 1.074 value = [2041620, 229038]
class = Non-Stop
True

False

MFCC 2 derivative <= 2.058 value = [1774382, 81420] class = Non-Stop

MFCC 1 derivative <= -0.319 value = [267238, 147618] class = Non-Stop

MFCC 2 derivative <= -1.676 value = [1751198, 490941] class = Non-Stop

Energy <= -0.272 value = [23184, 32329]
class = Stop

MFCC 4 <= 0.166 value = [34386, 96249]
class = Stop

Energy derivative <= -0.015 value = [232852, 51369] class = Non-Stop

MFCC 4 derivative <= -0.805 value = [63000, 29051] class = Non-Stop

Energy <= -0.541 value = [1688198, 20040]
class = Non-Stop

value = [0, 32329] class = Stop

value = [23184, 0] class = Non-Stop

value = [23051, 0] class = Non-Stop

MFCC 1 derivative <= -0.534 value = [11335, 96249] class = Stop

Energy <= -0.592 value = [30893, 43427]
class = Stop

MFCC 2 derivative <= -1.117 value = [201959, 7942] class = Non-Stop

Energy derivative <= 1.213 value = [11008, 29051] class = Stop

value = [51992, 0] class = Non-Stop

Energy derivative <= -0.42 value = [428353, 20040]
class = Non-Stop

value [ 1259845, 0] class = Non-Stop

value = [0, 73721] class = Stop

MFCC 3 derivative <= -0.047 value = [11335, 22528] class = Stop

MFCC 3 derivative <= -0.678 value = [14822, 40733] class = Stop

value = [16071, 2694] class = Non-Stop

value = [6189, 7942] class = Stop

value = [195770, 0] class = Non-Stop

value = [0, 25936] class = Stop

value = [11008, 3115] class = Non-Stop

MFCC 2 derivative <= 1.192 value = [33091, 8671] class = Non-Stop

MFCC 1 derivative <= -0.329 value = [395262, 11369] class = Non-Stop

value = [1156, 10342] class = Stop

MFCC 2 derivative <= -0.113 value = [10179, 12186] class = Stop

value = [0, 25373] class = Stop

MFCC 4 <= 0.532 value = [14822, 15360]
class = Stop

value = [25713, 0] class = Non-Stop

value = [7378, 8671] class = Stop

MFCC 4 <= 0.581 value = [86945, 11369]
class = Non-Stop

value = [308317, 0] class = Non-Stop

value = [2999, 7001] class = Stop

value = [7180, 5185] class = Non-Stop

value = [7440, 2757] class = Non-Stop

value = [7382, 12603] class = Stop

value = [65989, 0] class = Non-Stop

MFCC 2 <= 0.742 value = [20956, 11369]
class = Non-Stop

value = [14291, 3496] class = Non-Stop

value = [6665, 7873] class = Stop

MFCC 2 <= 1.074 value = [2052943, 217715]
class = Non-Stop

True

False

MFCC 2 derivative <= 2.058 value = [1807658, 48144] class = Non-Stop

MFCC 1 derivative <= -0.319 value = [245285, 169571] class = Non-Stop

MFCC 2 derivative <= -1.676 value = [1778423, 21866] class = Non-Stop

Energy <= -0.272 value = [29235, 26278]
class = Non-Stop

MFCC 4 <= 0.166 value = [18549, 112086]
class = Stop

Energy derivative <= -0.015 value = [226736, 57485] class = Non-Stop

MFCC 4 derivative <= -0.805 value = [70185, 21866] class = Non-Stop

value = [1708238, 0] class = Non-Stop

value = [9159, 23170] class = Stop

value = [20076, 3108] class = Non-Stop

value = [18549, 4502] class = Non-Stop

value = [0, 107584] class = Stop

Energy <= -0.605 value = [16835, 57483]
class = Stop

value = [209901, 0] class = Non-Stop

Energy derivative <= 0.772 value = [18193, 21866] class = Stop

value = [51992, 0] class = Non-Stop

value = [0, 54243] class = Stop

value = [16835, 3242] class = Non-Stop

value = [4748, 15281] class = Stop

value = [13445, 6585] class = Non-Stop

(a) GRU-HMM: Stop vs Non-Stop

(b) GRU-HMM: Stop vs Non-Stop

(c) GRU-HMM: Stop vs Non-Stop

Figure D.5: TIMIT task: Study of different regularization techniques for GRU-HMM model with 75 GRU nodes and 25 HMM states, trained to predict STOP phonemes. (a) Tradeoff curves showing how AUC predictive power and decision-tree complexity evolve with increasing regularization strength under L1, L2, or Tree regularization. (b) Example decision tree for λ = 3000.0. (c) Example decision tree for λ = 7000.0. When comparing with ﬁgure C.6b, this tree is signiﬁcantly smaller, suggesting that the GRU performs a different role in the residual model.

24

E Runtime comparisons
Training Time for Tree-Regularized Models. Table E.1 shows the wall time for training one epoch of each of the models presented in this paper using each of the datasets. Please note that the wall times for GRU-TREE and GRU-HMM-TREE include the cost of surrogate training. If the retraining frequency is small, then the amortized cost should be small.

Dataset
Signal-and-noise HMM Signal-and-noise HMM Signal-and-noise HMM Signal-and-noise HMM Signal-and-noise HMM SEPSIS SEPSIS SEPSIS SEPSIS SEPSIS TIMIT TIMIT TIMIT TIMIT TIMIT

Model
HMM GRU GRU-HMM GRU-TREE GRU-HMM-TREE HMM GRU GRU-HMM GRU-TREE GRU-HMM-TREE HMM GRU GRU-HMM GRU-TREE GRU-HMM-TREE

Epoch Time (Sec.)
16.66 ± 2.53 30.48 ± 1.92 50.40 ± 5.56 43.83 ± 3.84 73.24 ± 7.86 589.80 ± 24.11 822.27 ± 11.17 1 666.98 ± 147.00 2 015.15 ± 388.12 2 443.66 ± 351.22 1 668.96 ± 126.96 2 116.83 ± 438.83 3207.16 ± 651.85 3 977.01 ± 812.11 4 601.44 ± 805.88

Table E.1: Training time for recurrent models measured against all datasets used in this paper. Epoch time denotes the number of seconds it took for a single pass through all the training data. The epoch times for GRU-TREE and GRU-HMM-TREE include surrogate training expenses. If we retrain sparsely, then the cost of surrogate training is amortized and the epoch time for GRU and GRU-TREE, GRU-HMM and GRU-HMM-TREE are approximately the same. To measure epoch time, we used 10 HMM states, 10 GRU states, and 5 of each for GRU-HMM models. We trained the surrogate model for 5000 epochs. These tests were run on a single Intel Core i5 CPU.

25

F Extended Stability Tests
In the paper, we noted that decision trees are stable over multiple run. Here, we show that using the signal-and-noise HMM dataset, 10 independent runs with random initializations and λ = 1000.0 produce either the same or comparable trees. Additionally, we show that with weak regularization (λ = 0.01), the variability of the learned decision trees is high. Figures F.1, F.2 include examples of such trees on the signal-and-noise dataset. Similar results are found for real-world datasets.

X[0] <= 0.5 value = [4413, 587]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1867, 587]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [123, 587]
class = on

value = [0, 587] class = on

value = [123, 0] class = off

X[0] <= 0.5 value = [4467, 533]
class = off

True

False

value = [2546, 0] class = off

X[3] <= 0.5 value = [1921, 533]
class = off

value = [1744, 0] class = off

X[4] <= 0.5 value = [177, 533]
class = on

X[8] <= 0.5 value = [54, 533]
class = on

value = [123, 0] class = off

value = [0, 475] class = on

X[9] <= 0.5 value = [54, 58]
class = on

value = [0, 58] class = on

value = [54, 0] class = off

X[13] <= 0.5 value = [4901, 99]
class = off

True

False

value = [4514, 0] class = off

X[1] <= 0.5 value = [387, 99]
class = off

X[3] <= 0.5 value = [161, 99]
class = off

value = [226, 0] class = off

X[12] <= 0.5 value = [89, 99]
class = on

value = [72, 0] class = off

value = [89, 0] class = off

value = [0, 99] class = on

(a) 7/10 Runs

(b) 2/10 Runs

(c) 1/10 Runs

Figure F.1: Decision trees from 10 independent runs on the signal-and-noise HMM dataset with λ = 1000.0. Seven of the ten runs resulted in a tree of the same structure. The other three trees are similar, often having additional subtrees but sharing the same splits and features.

X[2] <= 0.5 value = [3149, 1851]
class = off

True

False

X[1] <= 0.5 value = [2267, 291]
class = off

X[1] <= 0.5 value = [882, 1560]
class = on

X[13] <= 0.5 value = [1006, 291]
class = off

value = [1261, 0] class = off

value = [0, 1244] class = on

X[4] <= 0.5 value = [882, 316]
class = off

X[4] <= 0.5 value = [1006, 154]
class = off

value = [0, 137] class = on

X[5] <= 0.5 value = [673, 316]
class = off

value = [209, 0] class = off

X[5] <= 0.5 value = [791, 154]
class = off

value = [215, 0] class = off

X[13] <= 0.5 value = [673, 237]
class = off

value = [0, 79] class = on

X[0] <= 0.5 value = [791, 88]
class = off

value = [0, 66] class = on

X[11] <= 0.5 value = [673, 167]
class = off

value = [0, 70] class = on

value = [453, 0] class = off

X[12] <= 0.5 value = [338, 88]
class = off

value = [606, 0] class = off

X[12] <= 0.5 value = [67, 167]
class = on

X[11] <= 0.5 value = [279, 88]
class = off

value = [59, 0] class = off

value = [0, 167] class = on

value = [67, 0] class = off

value = [279, 0] class = off

value = [0, 88] class = on

(a)

X[4] <= 0.5 value = [988, 4012]
class = on

True

False

X[2] <= 0.5 value = [332, 3755]
class = on

X[2] <= 0.5 value = [656, 257]
class = off

X[9] <= 0.5 value = [332, 1764]
class = on

value = [0, 1991] class = on

X[13] <= 0.5 value = [429, 33]
class = off

X[10] <= 0.5 value = [227, 224]
class = off

X[10] <= 0.5 value = [65, 1408]
class = on

X[10] <= 0.5 value = [267, 356]
class = on

value = [420, 0] class = off

value = [9, 33] class = on

X[13] <= 0.5 value = [227, 90]
class = off

value = [0, 134] class = on

X[13] <= 0.5 value = [65, 975]
class = on

value = [0, 433] class = on

X[3] <= 0.5 value = [267, 152]
class = off

value = [0, 204] class = on

X[3] <= 0.5 value = [225, 47]
class = off

value = [2, 43] class = on

X[3] <= 0.5 value = [65, 759]
class = on

value = [0, 216] class = on

X[6] <= 0.5 value = [267, 24]
class = off

value = [0, 128] class = on

value = [193, 0] class = off

X[9] <= 0.5 value = [32, 47]
class = on

X[6] <= 0.5 value = [65, 514]
class = on

value = [0, 245] class = on

value = [259, 0] class = off

value = [8, 24] class = on

value = [10, 32] class = on

value = [22, 15] class = off

X[5] <= 0.5 value = [65, 453]
class = on

value = [0, 61] class = on

value = [0, 453] class = on

value = [65, 0] class = off

X[12] <= 0.5 value = [1574, 3426]
class = on

True

False

X[2] <= 0.5 value = [902, 3112]
class = on

X[0] <= 0.5 value = [672, 314]
class = off

X[9] <= 0.5 value = [802, 1242]
class = on

X[9] <= 0.5 value = [100, 1870]
class = on

value = [494, 0] class = off

X[2] <= 0.5 value = [178, 314]
class = on

X[0] <= 0.5 value = [313, 979]
class = on

X[3] <= 0.5 value = [489, 263]
class = off

value = [0, 1192] class = on

X[0] <= 0.5 value = [100, 678]
class = on

X[13] <= 0.5 value = [146, 92]
class = off

X[4] <= 0.5 value = [32, 222]
class = on

X[11] <= 0.5 value = [313, 359]
class = on

value = [0, 620] class = on

X[10] <= 0.5 value = [419, 110]
class = off

X[8] <= 0.5 value = [70, 153]
class = on

X[3] <= 0.5 value = [100, 285]
class = on

value = [0, 393] class = on

X[10] <= 0.5 value = [146, 34]
class = off

value = [0, 58] class = on

value = [0, 204] class = on

value = [32, 18] class = off

X[3] <= 0.5 value = [236, 226]
class = off

X[10] <= 0.5 value = [77, 133]
class = on

X[0] <= 0.5 value = [322, 28]
class = off

X[4] <= 0.5 value = [97, 82]
class = off

X[10] <= 0.5 value = [70, 83]
class = on

value = [0, 70] class = on

X[10] <= 0.5 value = [100, 162]
class = on

value = [0, 123] class = on

value = [110, 0] class = off

X[11] <= 0.5 value = [36, 34]
class = off

X[8] <= 0.5 value = [236, 87]
class = off

value = [0, 139] class = on

X[13] <= 0.5 value = [77, 59]
class = off

value = [0, 74] class = on

value = [178, 0] class = off

X[4] <= 0.5 value = [144, 28]
class = off

X[0] <= 0.5 value = [68, 80]
class = on

value = [29, 2] class = off

X[0] <= 0.5 value = [70, 29]
class = off

value = [0, 54] class = on

X[8] <= 0.5 value = [100, 75]
class = off

value = [0, 87] class = on

value = [26, 9] class = off

value = [10, 25] class = on

value = [236, 0] class = off

value = [0, 87] class = on

X[3] <= 0.5 value = [76, 27]
class = off

value = [1, 32] class = on

X[8] <= 0.5 value = [115, 27]
class = off

value = [29, 1] class = off

value = [68, 0] class = off

value = [0, 80] class = on

value = [52, 0] class = off

value = [18, 29] class = on

X[11] <= 0.5 value = [100, 15]
class = off

value = [0, 60] class = on

value = [71, 0] class = off

value = [5, 27] class = on

value = [91, 0] class = off

value = [24, 27] class = on

value = [88, 0] class = off

value = [12, 15] class = on

(b)

(c)

X[1] <= 0.5 value = [3543, 1457]
class = off

True

False

X[10] <= 0.5 value = [2280, 261]
class = off

X[3] <= 0.5 value = [1263, 1196]
class = off

value = [1798, 0] class = off

X[3] <= 0.5 value = [482, 261]
class = off

X[6] <= 0.5 value = [629, 1091]
class = on

X[10] <= 0.5 value = [634, 105]
class = off

X[11] <= 0.5 value = [261, 261]
class = off

value = [221, 0] class = off

X[7] <= 0.5 value = [470, 1091]
class = on

value = [159, 0] class = off

value = [517, 0] class = off

X[11] <= 0.5 value = [117, 105]
class = off

X[6] <= 0.5 value = [105, 261]
class = on

value = [156, 0] class = off

X[11] <= 0.5 value = [337, 1091]
class = on

value = [133, 0] class = off

X[0] <= 0.5 value = [25, 105]
class = on

value = [92, 0] class = off

X[2] <= 0.5 value = [77, 260]
class = on

value = [28, 1] class = off

value = [0, 914] class = on

X[10] <= 0.5 value = [337, 177]
class = off

value = [0, 70] class = on

X[2] <= 0.5 value = [25, 35]
class = on

value = [0, 182] class = on

X[0] <= 0.5 value = [77, 78]
class = on

value = [337, 0] class = off

value = [0, 177] class = on

value = [10, 23] class = on

value = [15, 12] class = off

value = [0, 78] class = on

value = [77, 0] class = off

(d)

Figure F.2: Decision trees from 10 independent runs on the signal-and-noise HMM dataset with λ = 0.01. With low regularization, the variance in tree size and shape is high.

26

